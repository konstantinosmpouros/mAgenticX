{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f594c1ba-ca36-46e8-8789-8df62851f3c7",
   "metadata": {},
   "source": [
    "# OrthodoxAI - Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd36b1-71ca-4bd8-9e69-99206f25b0e4",
   "metadata": {},
   "source": [
    "> Konstantinos Mpouros <br>\n",
    "> Github: https://github.com/konstantinosmpouros?tab=repositories<br>\n",
    "> Year: 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8e8053-ccff-461b-9a96-8f44526620b1",
   "metadata": {},
   "source": [
    "## About the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b5c23-4989-4a01-a419-bfb4628abcba",
   "metadata": {},
   "source": [
    "This notebook is dedicated to prototyping and testing the behavior of individual and collaborative agents within the **OrthodoxAI** multi-agent system.\n",
    "\n",
    "It serves as a sandbox to:\n",
    "\n",
    "- Define agent roles (e.g., Reflection, Generator, Summarizer)\n",
    "- Simulate agent communication structure patters\n",
    "- Experiment with routing logic and agent chaining (without LangGraph)\n",
    "- Test prompt templates and output formatting for each agent\n",
    "- Evaluate performance and consistency across multiple LLM-backed tasks\n",
    "\n",
    "This notebook is used for isolated debugging and experimentation before integrating agents into the main production pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713835e-2b12-4806-b6c9-e771fed71705",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3edff7-c5f4-475b-93fa-94ab5882f936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:11.445871Z",
     "start_time": "2025-04-16T07:03:11.434871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the API Keys\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8e99c-6ea1-4992-a245-a1aae18bc630",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## OpenAI APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e6840-8369-42bb-b8d5-d898ef9bbfe7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Client Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd1076-2f94-49d4-8e08-ccbe70da8fd4",
   "metadata": {},
   "source": [
    "* Import libraries to chat with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551f9895-c065-4ddf-8390-a248bac20927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc06a6-cd92-42b1-a0c3-93a71003f565",
   "metadata": {},
   "source": [
    "* Define a Structured Output template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85a9871-35f4-44d1-b215-7618bd4d86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzerOutput(BaseModel):\n",
    "    classification: Literal[\"Religious\", \"Non-Religious\"] = Field(..., description=\"Either 'Religious' or 'Non-Religious'\")\n",
    "    key_topics: List[str] = Field(..., description=\"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",)\n",
    "    context_requirements: str = Field(..., description=\"A clear explanation of the query's context needs\")\n",
    "    query_complexity: Literal[\"Low\", \"Medium\", \"High\"] = Field(..., description=\"'Low', 'Medium', or 'High' complexity\")\n",
    "    reasoning: str = Field(..., description=\"The Chain of Thought that has been done in order to analyze the user query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ecee3e-adc7-49a8-b31e-b4a70ae0d995",
   "metadata": {},
   "source": [
    "* Initialize configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01b20ef-1bac-48d3-87b7-ba82518909ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'o3-mini'\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "chat_template = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant that classifies user queries as either religious or non-religious and extracts key topics.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Helloo!!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df3561-9013-418f-8a31-448bfc45bb4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Simple response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af41ee06-48d0-47dc-b860-4463cd0773e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "Key Topics: Greeting\n",
      "\n",
      "The query \"Helloo!!\" appears to be a friendly greeting with no religious content.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME, \n",
    "    messages=chat_template,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1e8da6-c71b-4d70-9f65-c5cdc649abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key Topic:\n",
      "• Greeting\n",
      "\n",
      "The user’s message appears to be a simple, informal greeting without any religious context.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=chat_template\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4541d-fe4c-409a-b7d1-372ed5cdfd8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Streaming response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f5344f-dc43-44ce-97ce-fb44b1ff8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key Topics: Greeting\n",
      "\n",
      "The message appears to be a friendly, informal greeting with no religious content."
     ]
    }
   ],
   "source": [
    "response = \"\"\n",
    "\n",
    "for chunk in client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=chat_template,\n",
    "    stream=True\n",
    "):\n",
    "    \n",
    "    if not chunk.choices:\n",
    "        continue  # Just a safeguard\n",
    "    \n",
    "    # The partial text is in 'delta.content'\n",
    "    chunk_text = chunk.choices[0].delta.content\n",
    "    if chunk_text is None:\n",
    "        continue\n",
    "\n",
    "    response += chunk_text\n",
    "    print(chunk_text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "115f69cc-b56e-4b7b-a606-6e35befe5496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key Topics: Greeting, informal salutation."
     ]
    }
   ],
   "source": [
    "stream = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=chat_template,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == 'response.refusal.delta':\n",
    "        print(event.delta, end=\"\")\n",
    "    elif event.type == 'response.output_text.delta':\n",
    "        print(event.delta, end=\"\")\n",
    "    elif event.type == 'response.error':\n",
    "        print(event.error, end=\"\")\n",
    "    elif event.type == 'response.completed':\n",
    "        response = event.response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ed8558-2b84-4dad-a86a-e722b8369fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_67eefa37c2048191b2860f006b1d9261003da8076e6768b6', summary=[], type='reasoning', status=None),\n",
       " ResponseOutputMessage(id='msg_67eefa381b208191931e99bd52493d89003da8076e6768b6', content=[ResponseOutputText(annotations=[], text='Classification: Non-religious\\n\\nKey Topics: Greeting, informal salutation.', type='output_text')], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654bc96-f254-4c71-a12e-e3e1600e049d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Structured response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8847254-15cd-4ee6-84f8-8b05c16e8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.chat.completions.parse(\n",
    "    model=MODEL_NAME,\n",
    "    messages=chat_template,\n",
    "    response_format=AnalyzerOutput\n",
    ")\n",
    "\n",
    "structured_object = response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d149aba4-67ce-4565-9e6a-e14c2d80bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(classification='Non-Religious', key_topics=['greeting'], context_requirements='No complexity is involved and there is no religious context present in the query. The query is simply a casual greeting.', query_complexity='Low', reasoning=\"The query 'Helloo!!' is a casual greeting with no mention of religious topics, symbols, or language. There is no indication of the conversation touching on religious themes, hence it is classified as non-religious and of low complexity.\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da3d419d-77cf-4978-b991-2f1822d5dd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\\n    \"greeting\"\\n  ],\\n  \"context_requirements\": \"No complexity is involved and there is no religious context present in the query. The query is simply a casual greeting.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The query \\'Helloo!!\\' is a casual greeting with no mention of religious topics, symbols, or language. There is no indication of the conversation touching on religious themes, hence it is classified as non-religious and of low complexity.\"\\n}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab4decd-6228-4d30-bb82-5a68537989c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "assistant\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.function_call)\n",
    "print(response.choices[0].message.tool_calls)\n",
    "print(response.choices[0].message.role)\n",
    "print(response.choices[0].message.refusal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "177fa1c9-4953-4dab-a5ac-a80a4d865546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4511/789635851.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  schema_dict = AnalyzerOutput.schema()\n"
     ]
    }
   ],
   "source": [
    "schema_dict = AnalyzerOutput.schema()\n",
    "schema_dict[\"additionalProperties\"] = False\n",
    "text_dict = {\n",
    "    \"format\": {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"name\": \"MyAnalyzerOutput\",  # arbitrary name\n",
    "        \"strict\": True,\n",
    "        \"schema\": schema_dict\n",
    "    }\n",
    "}\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=chat_template,\n",
    "    text=text_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653f33e6-dfb9-415f-a903-42979b5e6d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_67eefa3c1c608191a232cc4cc3cc9aa505b562a8227eead7', created_at=1743714876.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='o3-mini-2025-01-31', object='response', output=[ResponseReasoningItem(id='rs_67eefa3e69908191a96199dec3343ce505b562a8227eead7', summary=[], type='reasoning', status=None), ResponseOutputMessage(id='msg_67eefa3f67788191b6a07580c38dfaf905b562a8227eead7', content=[ResponseOutputText(annotations=[], text='{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\\n    \"greeting\"\\n  ],\\n  \"context_requirements\": \"The query is simply a casual greeting without any religious content or additional context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user message \\'Helloo!!\\' is a greeting and does not contain any content related to religious topics. Therefore, it is classified as non-religious with the key topic being a greeting.\"\\n}', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort='medium', generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatTextJSONSchemaConfig(name='MyAnalyzerOutput', schema_={'properties': {'classification': {'description': \"Either 'Religious' or 'Non-Religious'\", 'enum': ['Religious', 'Non-Religious'], 'title': 'Classification', 'type': 'string'}, 'key_topics': {'description': \"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\", 'items': {'type': 'string'}, 'title': 'Key Topics', 'type': 'array'}, 'context_requirements': {'description': \"A clear explanation of the query's context needs\", 'title': 'Context Requirements', 'type': 'string'}, 'query_complexity': {'description': \"'Low', 'Medium', or 'High' complexity\", 'enum': ['Low', 'Medium', 'High'], 'title': 'Query Complexity', 'type': 'string'}, 'reasoning': {'description': 'The Chain of Thought that has been done in order to analyze the user query', 'title': 'Reasoning', 'type': 'string'}}, 'required': ['classification', 'key_topics', 'context_requirements', 'query_complexity', 'reasoning'], 'title': 'AnalyzerOutput', 'type': 'object', 'additionalProperties': False}, type='json_schema', description=None, strict=True)), truncation='disabled', usage=ResponseUsage(input_tokens=36, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=423, output_tokens_details=OutputTokensDetails(reasoning_tokens=320), total_tokens=459), user=None, store=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024a7455-55d7-4d79-8cd0-0b3a442a53d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\\n    \"greeting\"\\n  ],\\n  \"context_requirements\": \"The query is simply a casual greeting without any religious content or additional context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user message \\'Helloo!!\\' is a greeting and does not contain any content related to religious topics. Therefore, it is classified as non-religious with the key topic being a greeting.\"\\n}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e0e4a8-ef99-43bd-802e-7c33047bfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseOutputText(annotations=[], text='{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\\n    \"greeting\"\\n  ],\\n  \"context_requirements\": \"The query is simply a casual greeting without any religious content or additional context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user message \\'Helloo!!\\' is a greeting and does not contain any content related to religious topics. Therefore, it is classified as non-religious with the key topic being a greeting.\"\\n}', type='output_text')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[1].content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a8341-3e6a-49e0-8132-ff89f9bd013c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multi-Step Structured Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5da65-0d59-4bf3-b8b4-8dca74ecd863",
   "metadata": {},
   "source": [
    "* Initialize the main template and the step's template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff2cc0c8-b610-4b71-a904-e15cca88be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5b53ab7-5af6-41b9-8fa4-8cac66d0b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
    "    ],\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a86bea6-3f00-4e0e-ae3b-40758b17a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_reasoning.refusal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de96d67d-7a44-4f1a-b023-786f1f50cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathReasoning(steps=[Step(explanation=\"The equation given is 8x + 7 = -23. We want to isolate the variable x. To do this, start by removing the constant term on the left side of the equation, which is 7. We'll do this by subtracting 7 from both sides of the equation.\", output='8x + 7 - 7 = -23 - 7'), Step(explanation='Subtracting 7 from both sides simplifies the equation. The left side becomes 8x, and the right side becomes -23 - 7, which is -30.', output='8x = -30'), Step(explanation='Now, we need to solve for x by isolating it. Since x is multiplied by 8, we do the opposite operation, which is dividing by 8, on both sides of the equation.', output='x = -30 / 8'), Step(explanation='Simplify the right side of the equation by performing the division. -30 divided by 8 simplifies to -3.75.', output='x = -3.75')], final_answer='x = -3.75')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "691a9dbd-f520-46c7-87af-7e0692718cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x = -3.75'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.parsed.final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49cead43-2452-412b-9276-0928e6a22ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Step(explanation=\"The equation given is 8x + 7 = -23. We want to isolate the variable x. To do this, start by removing the constant term on the left side of the equation, which is 7. We'll do this by subtracting 7 from both sides of the equation.\", output='8x + 7 - 7 = -23 - 7'),\n",
       " Step(explanation='Subtracting 7 from both sides simplifies the equation. The left side becomes 8x, and the right side becomes -23 - 7, which is -30.', output='8x = -30'),\n",
       " Step(explanation='Now, we need to solve for x by isolating it. Since x is multiplied by 8, we do the opposite operation, which is dividing by 8, on both sides of the equation.', output='x = -30 / 8'),\n",
       " Step(explanation='Simplify the right side of the equation by performing the division. -30 divided by 8 simplifies to -3.75.', output='x = -3.75')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.parsed.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0556a1-d37a-4656-9149-dd13d9347b81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Streaming Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c601a5d8-100d-4c91-8ba2-82a9e42c9a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4511/1884170164.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  schema_dict = AnalyzerOutput.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'classification': {'description': \"Either 'Religious' or 'Non-Religious'\",\n",
       "   'enum': ['Religious', 'Non-Religious'],\n",
       "   'title': 'Classification',\n",
       "   'type': 'string'},\n",
       "  'key_topics': {'description': \"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Key Topics',\n",
       "   'type': 'array'},\n",
       "  'context_requirements': {'description': \"A clear explanation of the query's context needs\",\n",
       "   'title': 'Context Requirements',\n",
       "   'type': 'string'},\n",
       "  'query_complexity': {'description': \"'Low', 'Medium', or 'High' complexity\",\n",
       "   'enum': ['Low', 'Medium', 'High'],\n",
       "   'title': 'Query Complexity',\n",
       "   'type': 'string'},\n",
       "  'reasoning': {'description': 'The Chain of Thought that has been done in order to analyze the user query',\n",
       "   'title': 'Reasoning',\n",
       "   'type': 'string'}},\n",
       " 'required': ['classification',\n",
       "  'key_topics',\n",
       "  'context_requirements',\n",
       "  'query_complexity',\n",
       "  'reasoning'],\n",
       " 'title': 'AnalyzerOutput',\n",
       " 'type': 'object',\n",
       " 'additionalProperties': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dict = AnalyzerOutput.schema()\n",
    "schema_dict[\"additionalProperties\"] = False\n",
    "schema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a390035-dbc1-45e8-9126-2f0385c5df4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': {'type': 'json_schema',\n",
       "  'name': 'MyAnalyzerOutput',\n",
       "  'schema': {'properties': {'classification': {'description': \"Either 'Religious' or 'Non-Religious'\",\n",
       "     'enum': ['Religious', 'Non-Religious'],\n",
       "     'title': 'Classification',\n",
       "     'type': 'string'},\n",
       "    'key_topics': {'description': \"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",\n",
       "     'items': {'type': 'string'},\n",
       "     'title': 'Key Topics',\n",
       "     'type': 'array'},\n",
       "    'context_requirements': {'description': \"A clear explanation of the query's context needs\",\n",
       "     'title': 'Context Requirements',\n",
       "     'type': 'string'},\n",
       "    'query_complexity': {'description': \"'Low', 'Medium', or 'High' complexity\",\n",
       "     'enum': ['Low', 'Medium', 'High'],\n",
       "     'title': 'Query Complexity',\n",
       "     'type': 'string'},\n",
       "    'reasoning': {'description': 'The Chain of Thought that has been done in order to analyze the user query',\n",
       "     'title': 'Reasoning',\n",
       "     'type': 'string'}},\n",
       "   'required': ['classification',\n",
       "    'key_topics',\n",
       "    'context_requirements',\n",
       "    'query_complexity',\n",
       "    'reasoning'],\n",
       "   'title': 'AnalyzerOutput',\n",
       "   'type': 'object',\n",
       "   'additionalProperties': False}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dict = {\n",
    "    \"format\": {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"name\": \"MyAnalyzerOutput\",  # arbitrary name\n",
    "        \"schema\": schema_dict\n",
    "    }\n",
    "}\n",
    "text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c74ceafa-f617-4147-8b98-e48d99c9cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"classification\": \"Non-Religious\",\n",
      "  \"key_topics\": [\"greeting\"],\n",
      "  \"context_requirements\": \"The query is a simple greeting message and does not imply any religious context.\",\n",
      "  \"query_complexity\": \"Low\",\n",
      "  \"reasoning\": \"The user's message 'Helloo!!' is a casual greeting without any religious elements. It falls under non-religious content, and the simplicity of the greeting means that the query is of low complexity.\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "stream = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=chat_template,\n",
    "    text=text_dict,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == 'response.refusal.delta':\n",
    "        print(event.delta, end=\"\")\n",
    "    elif event.type == 'response.output_text.delta':\n",
    "        print(event.delta, end=\"\")\n",
    "    elif event.type == 'response.error':\n",
    "        print(event.error, end=\"\")\n",
    "    elif event.type == 'response.completed':\n",
    "        response = event.response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3bf56d0-8171-4eef-8dce-86d2e8ae140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_67eefa4a0c588191a0db7699d16846980f551bba5511bb39', summary=[], type='reasoning', status=None),\n",
       " ResponseOutputMessage(id='msg_67eefa4acbec8191bedd9651ad84bf120f551bba5511bb39', content=[ResponseOutputText(annotations=[], text='{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\"greeting\"],\\n  \"context_requirements\": \"The query is a simple greeting message and does not imply any religious context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user\\'s message \\'Helloo!!\\' is a casual greeting without any religious elements. It falls under non-religious content, and the simplicity of the greeting means that the query is of low complexity.\"\\n}', type='output_text')], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee181dc1-467c-43b0-8eeb-b6343b9a17e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseReasoningItem(id='rs_67eefa4a0c588191a0db7699d16846980f551bba5511bb39', summary=[], type='reasoning', status=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6c17a89-fa55-4967-9943-6683422c2dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseOutputMessage(id='msg_67eefa4acbec8191bedd9651ad84bf120f551bba5511bb39', content=[ResponseOutputText(annotations=[], text='{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\"greeting\"],\\n  \"context_requirements\": \"The query is a simple greeting message and does not imply any religious context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user\\'s message \\'Helloo!!\\' is a casual greeting without any religious elements. It falls under non-religious content, and the simplicity of the greeting means that the query is of low complexity.\"\\n}', type='output_text')], role='assistant', status='completed', type='message')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fff3f5ad-e1d0-4352-95c0-4217e948e298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assistant'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1].role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b2d3fb2-d046-42f9-aa24-7fb13c9b2acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1].status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d51a2ac-8476-42b2-9c9e-e7a0c58ab15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\"greeting\"],\\n  \"context_requirements\": \"The query is a simple greeting message and does not imply any religious context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user\\'s message \\'Helloo!!\\' is a casual greeting without any religious elements. It falls under non-religious content, and the simplicity of the greeting means that the query is of low complexity.\"\\n}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1].content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac5aa6-2fca-466b-ba02-e7a19cc67ff6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Function Calling Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6b3d08e-fbe7-432c-9a01-39b01476a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for a given location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"City and country e.g. Bogotá, Colombia\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"location\"\n",
    "        ],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "707735f0-5fb3-4e41-bf61-4f11c242fafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_67eefa4c1c1c81918cf2ded63d178ee201399e5e5dcbafd3', created_at=1743714892.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='o3-mini-2025-01-31', object='response', output=[ResponseReasoningItem(id='rs_67eefa4cffb48191a0ad2433af706f7f01399e5e5dcbafd3', summary=[], type='reasoning', status=None), ResponseFunctionToolCall(arguments='{\"location\": \"Paris, France\"}', call_id='call_StVkKwib4bjRUbJtum2aip1G', name='get_weather', type='function_call', id='fc_67eefa4d79208191918dac892115886a01399e5e5dcbafd3', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='get_weather', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'City and country e.g. Bogotá, Colombia'}}, 'required': ['location'], 'additionalProperties': False}, strict=True, type='function', description='Get current temperature for a given location.')], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort='medium', generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=68, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=79, output_tokens_details=OutputTokensDetails(reasoning_tokens=64), total_tokens=147), user=None, store=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=[{\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"}],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3ea1eb3-3bb6-4cfc-b853-96e8dd33fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"location\": \"Paris, France\"}\n",
      "fc_67eefa4d79208191918dac892115886a01399e5e5dcbafd3\n",
      "function_call\n",
      "get_weather\n"
     ]
    }
   ],
   "source": [
    "print(response.output[1].arguments)\n",
    "print(response.output[1].id)\n",
    "print(response.output[1].type)\n",
    "print(response.output[1].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d1e56-5f44-44f9-be10-163b705fb49d",
   "metadata": {},
   "source": [
    "## Langchain LLM-Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815d4fd-cf6a-42c5-a725-5e44588c9776",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Langchain Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3005a-f51e-46c3-a4dd-714db9780330",
   "metadata": {},
   "source": [
    "* Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8e3be1-c962-4c26-94da-b17f9614b798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:26.262067Z",
     "start_time": "2025-04-16T07:03:25.330083Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de0eab-146f-472d-8e49-4b28607e85ce",
   "metadata": {},
   "source": [
    "* Initialize Structure Output template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe51cb6-2a8b-4674-b2fb-70ae9485e981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:26.772200Z",
     "start_time": "2025-04-16T07:03:26.760202Z"
    }
   },
   "outputs": [],
   "source": [
    "class AnalyzerOutput(BaseModel):\n",
    "    classification: Literal[\"Religious\", \"Non-Religious\"] = Field(..., description=\"Either 'Religious' or 'Non-Religious'\")\n",
    "    key_topics: List[str] = Field(..., description=\"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",)\n",
    "    context_requirements: str = Field(..., description=\"A clear explanation of the query's context needs\")\n",
    "    query_complexity: Literal[\"Low\", \"Medium\", \"High\"] = Field(..., description=\"'Low', 'Medium', or 'High' complexity\")\n",
    "    reasoning: str = Field(..., description=\"The Chain of Thought that has been done in order to analyze the user query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb277a-24e3-4b68-bc13-c8ae97fe2cd0",
   "metadata": {},
   "source": [
    "* Initialize configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03468a9e-0573-4c74-9e5c-99ec4fa411a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:29.165965Z",
     "start_time": "2025-04-16T07:03:29.153965Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'o3-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ca3cd-1d5b-4842-b59e-cf4c410d03ee",
   "metadata": {},
   "source": [
    "* Initialize prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384cd3ee-af74-4dd9-a466-9535575be0c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:30.579537Z",
     "start_time": "2025-04-16T07:03:30.561229Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant that classifies user queries as either religious or non-religious and extracts key topics.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Classify the following query and extract key concepts:\\n\\nQuery: {query}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant named {assistant_name}. Use the available tools to provide accurate information.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{user_input}\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c2c40-cabe-4dce-a754-1f1a907488ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f9c072-bb06-41b0-a103-018928ea1d1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T06:34:48.336273Z",
     "start_time": "2025-04-16T06:34:48.320270Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=MODEL_NAME)\n",
    "analyzer_chain = analyzer_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a934264-dc7d-48f2-8d40-d96c0f67bfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Classification: Non-religious\\n\\nKey Concepts:\\n• Greeting\\n• Salutation\\n• Casual communication', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 46, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_617f206dd9', 'finish_reason': 'stop', 'logprobs': None}, id='run-490abbfa-d40a-4703-9ec2-8adba68e51f3-0', usage_metadata={'input_tokens': 46, 'output_tokens': 95, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = analyzer_chain.invoke('Hello')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ab1aefe-e570-49f7-8fa9-a7a1eb6447bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key Concepts:\n",
      "• Greeting\n",
      "• Salutation\n",
      "• Casual communication \n",
      "\n",
      "\n",
      "{'token_usage': {'completion_tokens': 95, 'prompt_tokens': 46, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_617f206dd9', 'finish_reason': 'stop', 'logprobs': None} \n",
      "\n",
      "\n",
      "run-490abbfa-d40a-4703-9ec2-8adba68e51f3-0 \n",
      "\n",
      "\n",
      "{'input_tokens': 46, 'output_tokens': 95, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}\n"
     ]
    }
   ],
   "source": [
    "print(text.content, '\\n\\n')\n",
    "print(text.response_metadata, '\\n\\n')\n",
    "print(text.id, '\\n\\n')\n",
    "print(text.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944ffa9-e6af-4b1c-9d01-635950bcdabe",
   "metadata": {},
   "source": [
    "### Chain with Simple Response & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877a5ab3-a601-4e17-b496-c0292c35f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Fetches the current weather for a specified location.\"\"\"\n",
    "    # Placeholder implementation\n",
    "    return f\"The current weather in {location} is sunny with a temperature of 25°C.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f41bf7e-f734-4608-a594-0ac14dd33664",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=MODEL_NAME)\n",
    "llm_with_tools = llm.bind_tools([get_weather])\n",
    "chain = chat_prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf12e66-23d6-4013-b5f3-fd970724160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's the weather in Thessaloniki?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2df8ccf-4bad-499b-a2f8-9a5f0ebe0c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4MpDWsYBZjvyzHFfozCteWJK', 'function': {'arguments': '{\"location\": \"Thessaloniki\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 75, 'total_tokens': 101, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_c87fd29531', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1c8d2e06-c3bc-48af-84a3-59a1a95d4d18-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Thessaloniki'}, 'id': 'call_4MpDWsYBZjvyzHFfozCteWJK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 75, 'output_tokens': 26, 'total_tokens': 101, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de01b6e-12df-4669-b972-6c065e78ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'location': 'Thessaloniki'},\n",
       "  'id': 'call_4MpDWsYBZjvyzHFfozCteWJK',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e75e76-5cce-4b63-82ab-4e468eed46d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_weather',\n",
       " 'args': {'location': 'Thessaloniki'},\n",
       " 'id': 'call_4MpDWsYBZjvyzHFfozCteWJK',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65126128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(getattr(response, \"tool_calls\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d903491e-0ef4-48d0-9175-f2bd0680e0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_weather',\n",
       " 'args': {'location': 'Thessaloniki'},\n",
       " 'id': 'call_4MpDWsYBZjvyzHFfozCteWJK',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f4f0522-431f-403d-8d88-706046e0d4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51c9913c-4610-400f-aada-a20b8cff6608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tool_calls'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata['finish_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79a43f15-5dc1-4d2b-8fdf-858157ca25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's your name?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb61071f-db4a-4df5-9124-8f3bc741d235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My name is Athena. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 71, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_99801fd0cf', 'id': 'chatcmpl-BNGA2V1BN85izKhvvsSJDqqkgv09M', 'finish_reason': 'stop', 'logprobs': None}, id='run-0d7ca203-955b-484e-b893-3459d3cbb883-0', usage_metadata={'input_tokens': 71, 'output_tokens': 88, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d2a4c9b-1b7a-4b06-b4ee-0eee6ed2c559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb87deaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(getattr(response, \"tool_calls\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f558201-7e20-4998-a947-f0d2ba51eecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Athena. How can I assist you today?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b52806b6-e96b-47d2-aaa7-496dddca93a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stop'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata['finish_reason']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a803e-2f5d-4d39-95f0-b474efed49f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Streaming Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dbe4b66-4cc2-4f28-be86-3b27561bdb0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=MODEL_NAME, streaming=True)\n",
    "analyzer_chain = analyzer_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76b0d784-c7ba-456d-b058-63800a9c5646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key topics: Greeting, Salutation\n",
      "\n",
      "The query \"Hello!!\" is a casual greeting and does not contain any religious content."
     ]
    }
   ],
   "source": [
    "response = ''\n",
    "for token in analyzer_chain.stream('Hello!!'):\n",
    "    response += token.content\n",
    "    print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cf68537-5358-4293-9cda-e45d98e68137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Classification: Non-religious\\n\\nKey topics: Greeting, Salutation\\n\\nThe query \"Hello!!\" is a casual greeting and does not contain any religious content.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e9893-d7ba-4724-9d4f-dcce243f8be1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Streaming Response & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b8bee014-770b-4223-b52d-eb05eb813c63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:37.064970Z",
     "start_time": "2025-04-16T07:03:37.054968Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Fetches the current weather for a specified location.\"\"\"\n",
    "    # Placeholder implementation\n",
    "    return f\"The current weather in {location} is sunny with a temperature of 25°C.\"\n",
    "\n",
    "@tool\n",
    "def get_time(location: str) -> str:\n",
    "    \"\"\"Fetches the current time for a specified location.\"\"\"\n",
    "    # Placeholder implementation\n",
    "    return f\"The current time in {location} is 10:00AM.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c74110c8-af4d-4a2f-b79f-7093d441623f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:40.691450Z",
     "start_time": "2025-04-16T07:03:40.672450Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=MODEL_NAME, streaming=True)\n",
    "llm = llm.bind_tools([get_weather, get_time])\n",
    "chain = chat_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "29248a6c-8ffe-41e5-98bd-e2d6b4bd03c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:42.215924Z",
     "start_time": "2025-04-16T07:03:42.211924Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's your name?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "22eed1a5-8926-400f-a55d-3e7af0ca64e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:43.519789Z",
     "start_time": "2025-04-16T07:03:43.505789Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_tool_content(chunk, tool_calls):\n",
    "    if chunk.tool_call_chunks:\n",
    "        for tool_chunk in chunk.tool_call_chunks:\n",
    "            index = tool_chunk['index']\n",
    "            if index not in tool_calls:\n",
    "                tool_calls[index] = {\n",
    "                    'name': tool_chunk['name'],  # might be None at first\n",
    "                    'args': '',\n",
    "                    'id': tool_chunk['id']\n",
    "                }\n",
    "            if tool_chunk['name'] is not None:\n",
    "                tool_calls[index]['name'] = tool_chunk['name']\n",
    "            if tool_chunk['args']:\n",
    "                tool_calls[index]['args'] += tool_chunk['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac2f3e70-08e8-426e-8b6d-27e1db2ded75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:03:45.914677Z",
     "start_time": "2025-04-16T07:03:44.831798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Athena, your helpful assistant. How can I help you today?"
     ]
    }
   ],
   "source": [
    "response = ''\n",
    "tool_calls = {}\n",
    "\n",
    "for chunk in chain.stream(inputs):\n",
    "    response += chunk.content\n",
    "    print(chunk.content, end='', flush=True)\n",
    "    \n",
    "    extract_tool_content(chunk, tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "28b85c8a-bc25-420a-a322-4e2a4c9686e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "128645b2-a673-4bb3-8e65-90d81cef707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm Athena, your helpful assistant. How can I help you today?\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5e207cab-7f38-4f26-af0a-d81104a0b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's the weather like in Athens Greece and what your name?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f67739a0-f068-49b8-8530-d7b9572920d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ''\n",
    "tool_calls = {}\n",
    "\n",
    "for chunk in chain.stream(inputs):\n",
    "    response += chunk.content\n",
    "    print(chunk.content, end='', flush=True)\n",
    "    \n",
    "    extract_tool_content(chunk, tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "545c8a7c-0aa2-45ab-8bb4-3ef0eb19feee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'name': 'get_weather',\n",
       "  'args': '{\"location\": \"Athens, Greece\"}',\n",
       "  'id': 'call_UP86gO62T8ymwQpdXJBUlApA'}}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b35ec535-87f9-4980-a4f4-02a49295f83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3fcfa754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "06ba6d0a-3692-4557-a68b-a48945c006d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_weather',\n",
       " 'args': '{\"location\": \"Athens, Greece\"}',\n",
       " 'id': 'call_UP86gO62T8ymwQpdXJBUlApA'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls = tool_calls.pop(0)\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "73ed7ec7-25f6-43e9-9be6-3b360d27dfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_weather'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c130dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's the weather like in Athens Greece and what your name?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "887563d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_zTTCDbWDq8vSiQZvxVDrPhAB', 'function': {'arguments': '', 'name': 'get_weather'}, 'type': 'function'}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' tool_calls=[{'name': 'get_weather', 'args': {}, 'id': 'call_zTTCDbWDq8vSiQZvxVDrPhAB', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'get_weather', 'args': '', 'id': 'call_zTTCDbWDq8vSiQZvxVDrPhAB', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': '{\"', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' tool_calls=[{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}] tool_call_chunks=[{'name': None, 'args': '{\"', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': 'location', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' invalid_tool_calls=[{'name': None, 'args': 'location', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'location', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': '\":', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' invalid_tool_calls=[{'name': None, 'args': '\":', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': '\":', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': ' \"', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' invalid_tool_calls=[{'name': None, 'args': ' \"', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': ' \"', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': 'Ath', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' invalid_tool_calls=[{'name': None, 'args': 'Ath', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'Ath', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': 'ens', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' invalid_tool_calls=[{'name': None, 'args': 'ens', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': 'ens', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': ',', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' invalid_tool_calls=[{'name': None, 'args': ',', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': ',', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': ' Greece', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' invalid_tool_calls=[{'name': None, 'args': ' Greece', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': ' Greece', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': '\"}', 'name': None}, 'type': None}]} response_metadata={} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96' invalid_tool_calls=[{'name': None, 'args': '\"}', 'id': None, 'error': None, 'type': 'invalid_tool_call'}] tool_call_chunks=[{'name': None, 'args': '\"}', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'tool_calls', 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_99801fd0cf'} id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96'\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = ''\n",
    "tool_calls = {}\n",
    "\n",
    "for chunk in chain.stream(inputs):\n",
    "    print(chunk)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    extract_tool_content(chunk, tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9ef1fbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_99801fd0cf'}, id='run-9e493d58-206b-4d81-808d-4c0fd0e11b96')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fc9cdfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "if getattr(chunk, \"content\", None):\n",
    "    print(1)\n",
    "else:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e93334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"What's the weather forecast for Paris France today, and what's your name?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"Can you tell me the current weather in Tokyo Japan and also your name?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"How's the weather in Sydney Australia right now, and what do you go by?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"Could you check the weather in New York City and remind me of your name?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"What's the temperature like in Berlin Germany today, and what are you called?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"Can you update me on the weather in Dubai UAE and state your name?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"What's the climate like in Toronto Canada at this moment, and what's your name?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"How is the weather in Rome Italy this weekend, and may I know your name?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"Could you describe the weather conditions in Madrid Spain and share your name?\"},\n",
    "    {\"assistant_name\": \"Athena\", \"user_input\": \"What's the weather outlook for London UK tomorrow, and what's your name again?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d53d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"Paris, France\"}', 'id': 'call_FKhaZXqSrtkaHs7XUjB1fSnL'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"Tokyo, Japan\"}', 'id': 'call_HAXd69fHpmAFljPdb6K8qdJh'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"Sydney, Australia\"}', 'id': 'call_c8hEyT42fc2YSgzov0bgrpAk'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"New York City\"}', 'id': 'call_3osuInWOvPZEcblwiyJOspLs'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"Berlin, Germany\"}', 'id': 'call_cmwW92qnzjowRJvA15mQZyUi'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"Dubai, UAE\"}', 'id': 'call_sfsKbUpNS4GorxNoOAQFbrrL'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"Toronto, Canada\"}', 'id': 'call_eyQ0Okmxy2a8YjbpcmFTahfh'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"Rome, Italy\"}', 'id': 'call_LkJ7CFjbdb23Avkw5BAW4FBx'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"Madrid, Spain\"}', 'id': 'call_hZahEoWBFwJK5m8pco148sLA'}}\n",
      "{0: {'name': 'get_weather', 'args': '{\"location\": \"London UK\"}', 'id': 'call_M1BjcshreT5RWNI7HDP1yaKn'}}\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    response = ''\n",
    "    tool_calls = {}\n",
    "\n",
    "    for chunk in chain.stream(question):\n",
    "        response += chunk.content\n",
    "        print(chunk.content, end='', flush=True)\n",
    "        \n",
    "        extract_tool_content(chunk, tool_calls)\n",
    "    print(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77982622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'get_weather', 'args': '{\"location\": \"London UK\"}', 'id': 'call_M1BjcshreT5RWNI7HDP1yaKn'}\n"
     ]
    }
   ],
   "source": [
    "for call in tool_calls.values():\n",
    "    print(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb350d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-2024-08-06\", streaming=True)\n",
    "llm = llm.bind_tools([get_weather, get_time])\n",
    "llm = llm.bind(parallel_tool_calls=True)\n",
    "chain = chat_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e91151",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's the weather and time like in Athens Greece?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ''\n",
    "tool_calls = {}\n",
    "\n",
    "for chunk in chain.stream(inputs):\n",
    "    response += chunk.content\n",
    "    print(chunk.content, end='', flush=True)\n",
    "    \n",
    "    extract_tool_content(chunk, tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'name': 'get_weather',\n",
       "  'args': '{\"location\": \"Athens, Greece\"}',\n",
       "  'id': 'call_nJz1gNxWfFLZpc9qoA4yFjEc'},\n",
       " 1: {'name': 'get_time',\n",
       "  'args': '{\"location\": \"Athens, Greece\"}',\n",
       "  'id': 'call_LP6nKCFCJGwF43lzXeJJlB1n'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca86bac-a959-4c12-adb3-b69a6ca2eafe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Structure Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d80e9f3f-db3c-4dae-9fce-5e532be48d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_llm = ChatOpenAI(model=MODEL_NAME).with_structured_output(AnalyzerOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "823d487f-ec8d-41c8-8132-ac5a8515bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_chain = analyzer_prompt | analyzer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a90cc8ce-3ffe-4c4b-be51-162eecb4eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(classification='Non-Religious', key_topics=['Greetings', 'Salutation'], context_requirements=\"The query 'Hello' is a simple greeting with no additional context provided, and it does not contain religious themes or specific topics. More context would be needed if the query intended to delve into religious or complex topics.\", query_complexity='Low', reasoning=\"The query 'Hello' is a basic greeting and does not include any religious themes, practices, or terminology. It is classified as non-religious and is considered a low complexity query involving common conversational language.\")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = analyzer_chain.invoke('Hello')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d575e64-63b6-45cd-b4b3-70e2a78211be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Religious \n",
      "\n",
      "\n",
      "The query 'Hello' is a simple greeting with no additional context provided, and it does not contain religious themes or specific topics. More context would be needed if the query intended to delve into religious or complex topics. \n",
      "\n",
      "\n",
      "['Greetings', 'Salutation'] \n",
      "\n",
      "\n",
      "Low \n",
      "\n",
      "\n",
      "The query 'Hello' is a basic greeting and does not include any religious themes, practices, or terminology. It is classified as non-religious and is considered a low complexity query involving common conversational language. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text.classification, '\\n\\n')\n",
    "print(text.context_requirements, '\\n\\n')\n",
    "print(text.key_topics, '\\n\\n')\n",
    "print(text.query_complexity, '\\n\\n')\n",
    "print(text.reasoning, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db5bc60a-d440-4e68-a981-260438ca96d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.AnalyzerOutput"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af5453d9-f5b2-4811-91a7-cb7c6ba9e0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query 'Hello' is a basic greeting and does not include any religious themes, practices, or terminology. It is classified as non-religious and is considered a low complexity query involving common conversational language.\n",
      "\n",
      "The analysis of the user query shows that the question is Non-Religious and with a Low complexity. Specifically, the analysis said the following: The query 'Hello' is a simple greeting with no additional context provided, and it does not contain religious themes or specific topics. More context would be needed if the query intended to delve into religious or complex topics. Key topics: Greetings, Salutation.\n"
     ]
    }
   ],
   "source": [
    "analysis_report = (\n",
    "    f\"{text.reasoning}\\n\\n\"\n",
    "    f\"The analysis of the user query shows that the question is {text.classification} \"\n",
    "    f\"and with a {text.query_complexity} complexity. Specifically, the analysis said the following: \"\n",
    "    f\"{text.context_requirements} Key topics: {', '.join(text.key_topics)}.\"\n",
    ")\n",
    "print(analysis_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb284e-9314-45aa-9c80-6067956f7544",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Agentic Roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963b298-0900-4f48-81e4-711b2b298024",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summarizer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20d9c846-8f0c-4853-b220-042d79c6f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e9f6c31-6dca-47d1-b54d-130cfcd01643",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant called Summarization Agent that takes multiple retrieved text chunks related to a user query \"\n",
    "            \"and generates a concise and informative summary. \"\n",
    "            \"Your goal is to synthesize the content, extract key themes, facts, and insights, and present them in a well-structured summary along with citations if possible. \"\n",
    "            \"Avoid repetition, remove irrelevant details, and prioritize clarity, coherence, and theological accuracy when applicable.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the list of retrieved contents:\\n\\n{retrieved_chunks}\\n\\n\"\n",
    "            \"Summarize the content in a clear, structured way. Highlight key points, theological concepts, and any important distinctions. \"\n",
    "            \"Make sure the summary is helpful for answering the user's original question.\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e7411d-e1fa-4d43-b3cb-bb91345427c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- The Orthodox Church believes that icons are a window to the divine and play a vital role in worship.\\n\\n- Icons are venerated, not worshipped, and serve as tools for teaching and spiritual reflection.\\n\\n- The Seventh Ecumenical Council affirmed the use of icons in 787 AD, emphasizing their doctrinal importance.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_chunks = [\n",
    "    \"The Orthodox Church believes that icons are a window to the divine and play a vital role in worship.\",\n",
    "    \"Icons are venerated, not worshipped, and serve as tools for teaching and spiritual reflection.\",\n",
    "    \"The Seventh Ecumenical Council affirmed the use of icons in 787 AD, emphasizing their doctrinal importance.\"\n",
    "]\n",
    "\n",
    "formatted_chunks = \"\\n\\n\".join(f\"- {chunk}\" for chunk in retrieved_chunks)\n",
    "formatted_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad2350c8-e27e-4d5c-9604-f9dc29bd40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(model=REASONING_LLM_NAME,\n",
    "                 name=\"Summarizer Agent\")\n",
    "\n",
    "llm = ChatOpenAI(model=LLM_NAME,\n",
    "                 name=\"Summarizer Agent\",\n",
    "                 temperature=.8)\n",
    "\n",
    "summarizer_agent = summarizer_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe22b813-0b10-4e64-80c5-b7003752665b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The retrieved texts emphasize several important points about icons in the Orthodox Church:\n",
      "\n",
      "1. Icons are viewed as a window to the divine, playing a crucial role in worship by facilitating a connection between the believer and the sacred.\n",
      "2. They are venerated—not worshipped—which means they are respected as aids for teaching and spiritual reflection, rather than being objects of divine adoration themselves.\n",
      "3. The legitimacy and doctrinal value of icons were affirmed by the Seventh Ecumenical Council in 787 AD, underscoring their significance in the Church's tradition and theology (see texts 1, 2, and 3)."
     ]
    }
   ],
   "source": [
    "for token in summarizer_agent.stream(retrieved_chunks):\n",
    "    print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e900ec-03eb-4c87-a443-41b734150f3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Query Generation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea63fa95-18e2-4777-839f-dd1f02a66e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46bbe94b-836c-4588-ab5d-ff49a4b019b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalQueriesOutput(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"A list of concise and semantically meaningful queries derived from the user's original input, intended for searching in a vector database.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26d6847e-0beb-4daa-8824-4e4e242556e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_generator_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are an AI assistant called Retrieval Query Generator Agent that transforms user queries or instructions into a list of optimized retrieval queries. \"\n",
    "            \"These queries will be used to search a vector database for relevant information. \"\n",
    "            \"Ensure the queries are semantically rich, diverse if needed, and focused on capturing different possible interpretations or relevant subtopics. \"\n",
    "            \"Consider different angles and nuances of the user instruction, and aim for clarity and precision in each query.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\", \n",
    "            \"User input: {user_input}\\n\\n\"\n",
    "            \"Generate a list of search queries in natural language that capture the key aspects of the input. \"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2607acc2-6184-4ca8-abc5-79759b44a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=REASONING_LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Retrieval_Agent\"\n",
    ").with_structured_output(RetrievalQueriesOutput)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Retrieval_Agent\",\n",
    "    temperature=0\n",
    ").with_structured_output(RetrievalQueriesOutput)\n",
    "\n",
    "retrieval_agent = query_generator_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c605ad2-c6b4-421d-9622-efad598f1db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQueriesOutput(queries=['What role do icons play in the worship practices of the Orthodox Church?', 'How do icons influence the spiritual life and rituals in Orthodox liturgy?', 'What is the theological significance of icons in Eastern Orthodox worship?', 'In what ways are icons used to convey religious meaning in Orthodox traditions?', 'How are icons venerated and what symbolism do they hold in Orthodox Christian worship?', 'What is the historical and cultural importance of icons in the context of Orthodox worship?', 'How does the use of icons in Orthodox churches enhance the spiritual experience of believers?'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Explain the significance of icons in Orthodox worship.\"\n",
    "response = retrieval_agent.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "863b33d3-ff1f-4f4e-be97-3ba12f9e2d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What role do icons play in the worship practices of the Orthodox Church?',\n",
       " 'How do icons influence the spiritual life and rituals in Orthodox liturgy?',\n",
       " 'What is the theological significance of icons in Eastern Orthodox worship?',\n",
       " 'In what ways are icons used to convey religious meaning in Orthodox traditions?',\n",
       " 'How are icons venerated and what symbolism do they hold in Orthodox Christian worship?',\n",
       " 'What is the historical and cultural importance of icons in the context of Orthodox worship?',\n",
       " 'How does the use of icons in Orthodox churches enhance the spiritual experience of believers?']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b1437-16a4-49c3-9c4f-f16a96193979",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a88b390-9dac-4b25-b09c-1279c1b83dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caf6f5f6-1639-4015-872a-20eab3b6d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzerOutput(BaseModel):\n",
    "    classification: Literal[\"Religious\", \"Non-Religious\"] = Field(..., description=\"Either 'Religious' or 'Non-Religious'\")\n",
    "    key_topics: List[str] = Field(..., description=\"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",)\n",
    "    context_requirements: str = Field(..., description=\"A clear explanation of the query's context needs\")\n",
    "    query_complexity: Literal[\"Low\", \"Medium\", \"High\"] = Field(..., description=\"'Low', 'Medium', or 'High' complexity\")\n",
    "    reasoning: str = Field(..., description=\"The Chain of Thought that has been done in order to analyze the user query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1de0a0dd-ebee-43cf-b95c-bc47cc583642",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant that classifies user queries as either religious or non-religious and extracts key topics.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Classify the following query and extract key concepts:\\n\\nQuery: {query}\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "598d93f3-0a25-4a7d-b494-a939775df867",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=REASONING_LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Analyzer_Agent\"\n",
    ").with_structured_output(AnalyzerOutput)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Analyzer_Agent\",\n",
    "    temperature=0\n",
    ").with_structured_output(AnalyzerOutput)\n",
    "\n",
    "analyzer_agent = analyzer_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "934d2926-d423-4f19-b662-7b38f6c8c5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(classification='Religious', key_topics=['icons', 'Orthodox worship', 'religious symbolism', 'theology'], context_requirements='The query requires an explanation of the theological and liturgical role of icons in Orthodox worship, including historical and doctrinal context regarding their significance.', query_complexity='Low', reasoning='The query specifically asks about the significance of icons within Orthodox worship, indicating a focus on religious practices and symbolism. This clearly situates the question in a religious context, and the topics involved (icons, worship, symbolism) are directly related to religious studies.')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = analyzer_agent.invoke('Explain the significance of icons in Orthodox worship.')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c153ea6a-a47b-42d9-a543-2e3cb1ea374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Religious \n",
      "\n",
      "\n",
      "The query requires an explanation of the theological and liturgical role of icons in Orthodox worship, including historical and doctrinal context regarding their significance. \n",
      "\n",
      "\n",
      "['icons', 'Orthodox worship', 'religious symbolism', 'theology'] \n",
      "\n",
      "\n",
      "Low \n",
      "\n",
      "\n",
      "The query specifically asks about the significance of icons within Orthodox worship, indicating a focus on religious practices and symbolism. This clearly situates the question in a religious context, and the topics involved (icons, worship, symbolism) are directly related to religious studies. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.classification, '\\n\\n')\n",
    "print(response.context_requirements, '\\n\\n')\n",
    "print(response.key_topics, '\\n\\n')\n",
    "print(response.query_complexity, '\\n\\n')\n",
    "print(response.reasoning, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01b872-b418-41d8-b5a7-71f44e1c2d03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reflection Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7655213-cbca-4b48-8652-1820c9ebdd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54268695-2ca4-40e8-8b0d-6b2f792c213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionOutput(BaseModel):\n",
    "    reflection: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Detailed commentary on the final answer. Should analyze the correctness, clarity, and completeness \"\n",
    "            \"of the answer, and note any missing information or conflicting details.\")\n",
    "    )\n",
    "    requires_additional_retrieval: bool = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"If True, indicates the final answer did not fully address the user's query, and the agent should \"\n",
    "            \"re-run the retrieval process to gather more context or data.\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a29b3617-315b-4f59-9464-bafc32fd9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a reflection agent. Your goal is to assess the final answer produced by the previous generation step. \"\n",
    "            \"Review the user's original query and the generated answer. Provide a thoughtful reflection on the answer’s correctness, \"\n",
    "            \"clarity, completeness, and any areas that could be improved or expanded.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"User Query:\\n{user_query}\\n\\n\"\n",
    "            \"Generated Answer:\\n{generated_answer}\\n\\n\"\n",
    "            \"Reflect on this answer, noting if it fully addresses the user's question, whether there are any gaps or inaccuracies, \"\n",
    "            \"and if further clarification is necessary. Provide your analysis.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0274229-4b61-4c90-8286-d29f3b9fe384",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=REASONING_LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Reflection_Agent\"\n",
    ").with_structured_output(ReflectionOutput)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Reflection_Agent\",\n",
    "    temperature=0\n",
    ").with_structured_output(ReflectionOutput)\n",
    "\n",
    "reflection_agent = reflection_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09eed6b9-3e28-4f7f-a77d-c7b11ef8fe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReflectionOutput(reflection=\"The answer provided is clear, accurate, and addresses the core aspects of the significance of icons in Orthodox worship. It correctly explains that icons serve as windows to the divine, are important aids for veneration and prayer, and play a role in theological teaching by linking worshippers with the Incarnate Christ. The explanation that icons are not worshipped as idols but are venerated, with the honor transferred to the prototype they represent, is essential and was properly included. Additionally, the reference to the Seventh Ecumenical Council (787 AD) helps to anchor the explanation in historical and doctrinal context. One possible area for further elaboration might include expanding on the role of icons as visual theology and spiritual aids that help the faithful to connect with the mysteries of faith, or mentioning their aesthetic importance in liturgical settings, which would add greater depth to the answer. Overall, the answer is thorough and meets the user's query effectively.\", requires_additional_retrieval=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"user_query\": \"What is the significance of icons in Orthodox worship?\",\n",
    "    \"generated_answer\": \"Icons in Orthodox Christianity are viewed as windows to the divine, \"\n",
    "        \"serving as important aids for veneration, prayer, and theological teaching. \"\n",
    "        \"They are treated with great respect, though not worshiped as idols. \"\n",
    "        \"Historically, the Seventh Ecumenical Council (787 AD) affirmed the use of icons, \"\n",
    "        \"emphasizing their doctrinal importance. This council clarified that the honor \"\n",
    "        \"shown to an icon passes on to the prototype it represents, aligning the practice \"\n",
    "        \"with Orthodox teachings on the Incarnation and the sanctification of matter.\"\n",
    "}\n",
    "reflection = reflection_agent.invoke(input=inputs)\n",
    "reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98e8764d-a343-49d4-b1dc-511973b25b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer provided is clear, accurate, and addresses the core aspects of the significance of icons in Orthodox worship. It correctly explains that icons serve as windows to the divine, are important aids for veneration and prayer, and play a role in theological teaching by linking worshippers with the Incarnate Christ. The explanation that icons are not worshipped as idols but are venerated, with the honor transferred to the prototype they represent, is essential and was properly included. Additionally, the reference to the Seventh Ecumenical Council (787 AD) helps to anchor the explanation in historical and doctrinal context. One possible area for further elaboration might include expanding on the role of icons as visual theology and spiritual aids that help the faithful to connect with the mysteries of faith, or mentioning their aesthetic importance in liturgical settings, which would add greater depth to the answer. Overall, the answer is thorough and meets the user's query effectively.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(reflection.reflection)\n",
    "print(reflection.requires_additional_retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5169c93a-c779-4a2c-b698-94dfffd71e55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799a30d6-c8c5-420c-8929-1ce8dea9dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438a7c1f-7771-4745-8187-30e1a05b43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are an AI assistant called Generation Agent with extensive knowledge of Christian Orthodox theology and history. \"\n",
    "            \"You have been provided with the user's question and a summarized context derived from relevant sources. \"\n",
    "            \"Use the information in the summary to ensure your answer is accurate, coherent, and consistent with the described theological points.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"User query: {user_query}\\n\\n\"\n",
    "            \"Relevant content summary:\\n{retrieved_summary}\\n\\n\"\n",
    "            \"Based on the above summary and your own knowledge, provide a complete and accurate answer. \"\n",
    "            \"If the summary does not contain the required detail, do your best to fill in the gaps using your background knowledge, \"\n",
    "            \"staying consistent with the theological principles outlined.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4097b6a0-f698-4fd6-953d-bb5cd71187f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=REASONING_LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Generation_Agent\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Generation_Agent\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "generation_agent = generation_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4782aa7-c6be-43e2-b01e-f0c08b79d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_inputs = {\n",
    "    \"user_query\": \"How do icons fit into Orthodox worship?\",\n",
    "    \"retrieved_summary\": (\n",
    "        \"From the retrieved sources: Icons are integral to Orthodox Christian practice, \"\n",
    "        \"functioning as tangible reflections of the Incarnation. They are venerated \"\n",
    "        \"(not worshiped), with the understanding that honor paid to an icon passes \"\n",
    "        \"on to the individual or event depicted. Historically, the Seventh Ecumenical \"\n",
    "        \"Council in 787 AD affirmed the use of icons, emphasizing their doctrinal and \"\n",
    "        \"liturgical importance in teaching and worship.\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8e469a-58e8-4754-9630-e5256c79a61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Orthodox Christianity, icons hold a central place in worship and spiritual life. They are not considered objects of worship in themselves; rather, icons are venerated as windows to the divine, offering a tangible reflection of the Incarnation. When the faithful show honor to an icon, the veneration is understood to be directed toward the person or event it represents.\n",
      "\n",
      "The Seventh Ecumenical Council in 787 AD affirmed the use of icons as a legitimate and essential part of Orthodox practice. This council taught that icons serve not only as artistic representations but also as theological tools. They help convey the mystery of God’s intervention in human history—most notably, the incarnation of Christ—making divine realities accessible to the human mind and heart.\n",
      "\n",
      "In the liturgical context, icons are used to focus prayer, aid in meditation, and connect the worshiper with the saints and holy events of salvation history. They provide a visual reminder that God entered into human nature, which underpins the entire Orthodox understanding of salvation. Thus, icons play both an educational and a devotional role: They instruct the faithful in the tenets of the faith and support a spiritual encounter with God.\n",
      "\n",
      "In summary:\n",
      "• Icons serve as a visible link between heaven and earth, symbolizing the reality of the Incarnation.\n",
      "• They are venerated (honored) rather than worshiped, with the honor given to the icon passed on to its subject.\n",
      "• Historically, their use was defended and affirmed by the Church, particularly through the Seventh Ecumenical Council, highlighting their role in teaching and expressing the faith.\n",
      "\n",
      "This understanding underscores why icons remain indispensable in Orthodox worship—they continue to inspire and sustain the spiritual life of the community by connecting the material with the transcendent."
     ]
    }
   ],
   "source": [
    "for token in generation_agent.stream(input=generation_inputs):\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9f0d8-fef3-4007-809c-45a7b76cd66a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Langchain Prebuild Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45d623-7a65-4940-8126-9746fe9495b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### React Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca87920c-cdb5-4801-8cbd-4bbe5fee2a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostasbouros/.local/lib/python3.10/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to create an image of a Halloween night set in a haunted museum. I want the image to embody a spooky atmosphere with details such as eerie lighting, ghostly apparitions, ancient exhibits, cobwebs, and flickering candles that enhance the haunted vibe of the scene.\n",
      "\n",
      "Action: openai_dalle  \n",
      "Action Input: \"A Halloween night at a haunted museum, eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs and flickering candles, full moon in the background creating a spooky atmosphere, detailed and atmospheric.\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-2qwmDV9Ve2gTEzSZLdQ14cEq.png?st=2025-04-11T21%3A41%3A58Z&se=2025-04-11T23%3A41%3A58Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T20%3A07%3A09Z&ske=2025-04-12T20%3A07%3A09Z&sks=b&skv=2024-08-04&sig=0IbVLA5qZFo/dhULmDiiUDJHqM4UJceg4GMNSCD2w6Y%3D\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: Create an image of a Halloween night at a haunted museum  \n",
      "Thought: I need to create an image that captures a spooky atmosphere at a haunted museum during Halloween. I envision eerie lighting, ghostly apparitions, ancient exhibits, cobwebs, and flickering candles, all under a full moon to enhance the haunted ambiance.  \n",
      "Action: openai_dalle  \n",
      "Action Input: \"A Halloween night at a haunted museum, eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs and flickering candles, full moon in the background creating a spooky atmosphere, detailed and atmospheric.\"  \u001b[0m\u001b[36;1m\u001b[1;3mhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-HFvQNYd8PIrEtzo1yql8PxHK.png?st=2025-04-11T21%3A42%3A13Z&se=2025-04-11T23%3A42%3A13Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T16%3A50%3A47Z&ske=2025-04-12T16%3A50%3A47Z&sks=b&skv=2024-08-04&sig=GZZiMWtGBcrSfVFcxMjsnT%2BC11iUWnxmg4Zk8YNUjrA%3D\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to create an image depicting a Halloween night in a haunted museum. The image should include eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs, and flickering candles, all illuminated by a full moon to create a spooky atmosphere.\n",
      "Action: openai_dalle\n",
      "Action Input: \"A Halloween night at a haunted museum, eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs and flickering candles, full moon in the background creating a spooky atmosphere, detailed and atmospheric.\"\u001b[0m\u001b[36;1m\u001b[1;3mhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-WQQByALWZYBniUuUXTfo7ehG.png?st=2025-04-11T21%3A42%3A34Z&se=2025-04-11T23%3A42%3A34Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T07%3A09%3A31Z&ske=2025-04-12T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=jBasG%2BIdDVJqT0qKCsavtlHxSHqm8MhD1V0%2BRgfhgfQ%3D\u001b[0m\u001b[32;1m\u001b[1;3mThought: I generated a detailed image according to the description: a Halloween night at a haunted museum with eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs, flickering candles, and a full moon casting a spooky glow over the scene.\n",
      "Final Answer: Here is your image of a Halloween night at a haunted museum:\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-WQQByALWZYBniUuUXTfo7ehG.png?st=2025-04-11T21%3A42%3A34Z&se=2025-04-11T23%3A42%3A34Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T07%3A09%3A31Z&ske=2025-04-12T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=jBasG%2BIdDVJqT0qKCsavtlHxSHqm8MhD1V0%2BRgfhgfQ%3D\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final Result:\n",
      " {'input': 'Create an image of a Halloween night at a haunted museum', 'output': 'Here is your image of a Halloween night at a haunted museum:\\nhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-WQQByALWZYBniUuUXTfo7ehG.png?st=2025-04-11T21%3A42%3A34Z&se=2025-04-11T23%3A42%3A34Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T07%3A09%3A31Z&ske=2025-04-12T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=jBasG%2BIdDVJqT0qKCsavtlHxSHqm8MhD1V0%2BRgfhgfQ%3D'}\n"
     ]
    }
   ],
   "source": [
    "# Tool\n",
    "from langchain_community.tools.openai_dalle_image_generation import OpenAIDALLEImageGenerationTool\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "# Ready prompt for react agent\n",
    "from langchain import hub\n",
    "\n",
    "# ReAct Agent\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"o3-mini\")\n",
    "\n",
    "# DALL·E Tool\n",
    "dalle_tool = OpenAIDALLEImageGenerationTool(api_wrapper=DallEAPIWrapper())\n",
    "tools = [dalle_tool]\n",
    "\n",
    "# Agent\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Wrap in executor\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Run\n",
    "user_prompt = \"Create an image of a Halloween night at a haunted museum\"\n",
    "response = executor.invoke({\"input\": user_prompt})\n",
    "\n",
    "print(\"\\nFinal Result:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a4bb30-a4f8-48e6-8e76-905ed2952de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your image of a Halloween night at a haunted museum:\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-WQQByALWZYBniUuUXTfo7ehG.png?st=2025-04-11T21%3A42%3A34Z&se=2025-04-11T23%3A42%3A34Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T07%3A09%3A31Z&ske=2025-04-12T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=jBasG%2BIdDVJqT0qKCsavtlHxSHqm8MhD1V0%2BRgfhgfQ%3D\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b78961a-f6ce-45e2-aaa9-7b97632cd73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAction(tool='openai_dalle', tool_input='A spooky haunted museum on a Halloween night, with ghostly apparitions, eerie antique exhibits, dim lighting, pumpkins, and cobwebs, surrounded by a misty, mysterious atmosphere.', log='Question: Create an image of a Halloween night at a haunted museum  \\nThought: I need to generate an image that conveys a spooky, atmospheric setting typical of a haunted museum on Halloween night. I will include elements such as eerie lighting, ghostly apparitions, ancient exhibits, pumpkins, and cobwebs to capture the haunted ambiance.  \\nAction: openai_dalle  \\nAction Input: \"A spooky haunted museum on a Halloween night, with ghostly apparitions, eerie antique exhibits, dim lighting, pumpkins, and cobwebs, surrounded by a misty, mysterious atmosphere.\"  ')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\n",
    "    \"input\": user_prompt,\n",
    "    \"intermediate_steps\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0af0fa4a-481c-4873-9e29-41b674b79b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e35e83-e483-4782-874b-e33ce7a8b40a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LangGraph Prebuild Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c1b6e-6995-4b36-a7ad-c665450bd3f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c1d0e8-510e-4f56-9a12-e5ba4fa43fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0801a57-a4b5-46a2-918b-6ae0f1afcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}'\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], \n",
    "    subject: str, \n",
    "    duration_minutes: int, \n",
    "    preferred_day: str\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    return f\"Meeting '{subject}' scheduled for {preferred_day} with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1418c3d5-0969-4b0e-8def-26fb13e3974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=\"openai:o3-mini\",\n",
    "    tools=[write_email, schedule_meeting, check_calendar_availability],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d8f43d2-9964-4342-8347-9dbb71a19634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='write me an email from my director to thank him for his kind words pls', additional_kwargs={}, response_metadata={}, id='22303341-2fb9-4507-8c1d-421a00ad5c61'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uDnNeQXlyKJLtwfRyshBcSRz', 'function': {'arguments': '{\\n  \"to\": \"director@example.com\",\\n  \"subject\": \"Thank You for Your Kind Words\",\\n  \"content\": \"Dear [Director\\'s Name],\\\\n\\\\nI hope this message finds you well. I wanted to take a moment to express my sincere gratitude for your kind words and encouragement. Your feedback has not only boosted my confidence but also reinforced my commitment to contributing in every possible way to our team’s success.\\\\n\\\\nYour thoughtful reminder of the positive impact my work can have means a great deal to me, and it inspires me to strive for even higher standards. I truly appreciate your leadership and the supportive work environment you help foster.\\\\n\\\\nThank you once again for your kind words and for always being a source of guidance. I look forward to continuing to work together and to progressing further under your mentorship.\\\\n\\\\nWarm regards,\\\\n[Your Name]\"\\n}', 'name': 'write_email'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1283, 'prompt_tokens': 124, 'total_tokens': 1407, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1088, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_99801fd0cf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2930f600-b5ac-499a-a119-abe273cccfb5-0', tool_calls=[{'name': 'write_email', 'args': {'to': 'director@example.com', 'subject': 'Thank You for Your Kind Words', 'content': \"Dear [Director's Name],\\n\\nI hope this message finds you well. I wanted to take a moment to express my sincere gratitude for your kind words and encouragement. Your feedback has not only boosted my confidence but also reinforced my commitment to contributing in every possible way to our team’s success.\\n\\nYour thoughtful reminder of the positive impact my work can have means a great deal to me, and it inspires me to strive for even higher standards. I truly appreciate your leadership and the supportive work environment you help foster.\\n\\nThank you once again for your kind words and for always being a source of guidance. I look forward to continuing to work together and to progressing further under your mentorship.\\n\\nWarm regards,\\n[Your Name]\"}, 'id': 'call_uDnNeQXlyKJLtwfRyshBcSRz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 124, 'output_tokens': 1283, 'total_tokens': 1407, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1088}}),\n",
       "  ToolMessage(content=\"Email sent to director@example.com with subject 'Thank You for Your Kind Words'\", name='write_email', id='fc8504d8-0278-4442-907a-5f7988e452f9', tool_call_id='call_uDnNeQXlyKJLtwfRyshBcSRz'),\n",
       "  AIMessage(content='The email has been sent to your director. Let me know if you need any further assistance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 331, 'total_tokens': 362, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_99801fd0cf', 'finish_reason': 'stop', 'logprobs': None}, id='run-893bcc69-523e-46a8-bb95-8885c841eed4-0', usage_metadata={'input_tokens': 331, 'output_tokens': 31, 'total_tokens': 362, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"write me an email from my director to thank him for his kind words pls\"\n",
    "response = agent.invoke({\"messages\": query})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91719c32-361f-4983-8eb6-288000cd549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "write me an email from my director to thank him for his kind words pls\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_email (call_uDnNeQXlyKJLtwfRyshBcSRz)\n",
      " Call ID: call_uDnNeQXlyKJLtwfRyshBcSRz\n",
      "  Args:\n",
      "    to: director@example.com\n",
      "    subject: Thank You for Your Kind Words\n",
      "    content: Dear [Director's Name],\n",
      "\n",
      "I hope this message finds you well. I wanted to take a moment to express my sincere gratitude for your kind words and encouragement. Your feedback has not only boosted my confidence but also reinforced my commitment to contributing in every possible way to our team’s success.\n",
      "\n",
      "Your thoughtful reminder of the positive impact my work can have means a great deal to me, and it inspires me to strive for even higher standards. I truly appreciate your leadership and the supportive work environment you help foster.\n",
      "\n",
      "Thank you once again for your kind words and for always being a source of guidance. I look forward to continuing to work together and to progressing further under your mentorship.\n",
      "\n",
      "Warm regards,\n",
      "[Your Name]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_email\n",
      "\n",
      "Email sent to director@example.com with subject 'Thank You for Your Kind Words'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The email has been sent to your director. Let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431604c6-4c21-4610-b61a-cb5140f7a8d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28b17f-51eb-4688-92f7-93b5600195c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_supervisor import create_supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec720c-f24e-41b1-8886-2c0a9073d4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19de5d6-3cd4-4387-8120-09557c691263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "832cf2c9-07be-4c6e-9555-b28e020b1e9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Custome Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c0fe4-5d8b-4670-8a3c-0685f7eda7e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ReAct Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f17b7-da72-4630-9fa4-b3d631a73726",
   "metadata": {},
   "source": [
    "* Setup the classes and the variables needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "86bd5ffc-6f24-4a79-aefb-9a0ede35a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Union, List, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.messages import ToolMessage, AIMessageChunk\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "class ReAct_Agent:\n",
    "    \"\"\"\n",
    "    A ReAct-style agent that interacts with an LLM and invokes tools when needed.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): The name of the agent.\n",
    "        llm (Union[ChatOpenAI, ChatAnthropic]): The language model used for generation.\n",
    "        system_prompt (SystemMessage): The system prompt wrapped in a SystemMessage.\n",
    "        tools (Dict[str, Tool]): A mapping of tool names to Tool instances.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                name: str,\n",
    "                llm: Union[ChatOpenAI, ChatAnthropic],\n",
    "                system_prompt: str,\n",
    "                tools: Dict[str, Tool] = []):\n",
    "        # Initialize basic attributes of the agent\n",
    "        self.name = name\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.system_prompt = SystemMessage(system_prompt.format(name=self.name))\n",
    "\n",
    "        # Bind the LLM with the give tools if passed\n",
    "        self.llm = self.llm.bind_tools(tools.values()) if tools else self.llm\n",
    "\n",
    "    def invoke(self, message: Union[str, HumanMessage, ChatPromptTemplate]):\n",
    "        \"\"\"\n",
    "        Invoke the agent with the given message, handling tool calls in a ReAct loop.\n",
    "\n",
    "        Args:\n",
    "            message (Union[str, HumanMessage, ChatPromptTemplate]): The user message or prompt template.\n",
    "\n",
    "        Returns:\n",
    "            ChatPromptTemplate: The final chat template containing the full conversation.\n",
    "        \"\"\"\n",
    "        chat_template = self._build_chat_template(message)\n",
    "        response = self.llm.invoke(chat_template.messages)\n",
    "        chat_template = ChatPromptTemplate.from_messages(chat_template.messages + [response])\n",
    "\n",
    "        while self._is_tool_call(response):\n",
    "            tool_results = self._execute_tool(response.tool_calls[0])\n",
    "\n",
    "            # Build a *new* template that includes everything so far plus the tool result\n",
    "            chat_template = ChatPromptTemplate.from_messages(\n",
    "                chat_template.messages + [tool_results]\n",
    "            )\n",
    "\n",
    "            # Run the inference again.\n",
    "            response = self.llm.invoke(chat_template.messages)\n",
    "\n",
    "            chat_template = ChatPromptTemplate.from_messages(\n",
    "                chat_template.messages + [response]\n",
    "            )\n",
    "        \n",
    "        return chat_template\n",
    "\n",
    "    def stream(self, message: Union[str, HumanMessage, ChatPromptTemplate]):\n",
    "        \"\"\"\n",
    "        Stream the agent's response content, handling tool calls incrementally.\n",
    "\n",
    "        Args:\n",
    "            message (Union[str, HumanMessage, ChatPromptTemplate]): The user message or prompt template.\n",
    "\n",
    "        Yields:\n",
    "            str: Content chunks from the LLM's streaming output.\n",
    "        \"\"\"\n",
    "        chat_template = self._build_chat_template(message)\n",
    "\n",
    "        tool_calls = {}\n",
    "        ai_msg = AIMessage(content=\"\")\n",
    "        for chunk in self.llm.stream(chat_template.messages):\n",
    "            # Extract tool‑call pieces (if any)\n",
    "            if getattr(chunk, \"tool_call_chunks\", None):\n",
    "                tool_calls = self._stream_tool_content_extraction(chunk, tool_calls)\n",
    "\n",
    "            # Yield actual text content if provided\n",
    "            if getattr(chunk, \"content\", None):\n",
    "                ai_msg.content += chunk.content\n",
    "                yield chunk.content\n",
    "\n",
    "        # ReAct loop – keep going while model asked for tools\n",
    "        while tool_calls:\n",
    "            # Take a Tool Message for every tool call we have\n",
    "            while tool_calls:\n",
    "                # Pop the first tool call and fix the args\n",
    "                tool_call = tool_calls.pop(0)\n",
    "                if isinstance(tool_call['args'], str):\n",
    "                    tool_call['args'] = json.loads(tool_call['args'])\n",
    "\n",
    "                # Append in the history an AI Message with the this tool call params\n",
    "                ai_msg.tool_calls = [tool_call]\n",
    "                chat_template = ChatPromptTemplate.from_messages(chat_template.messages + [ai_msg])\n",
    "\n",
    "                # Execute the tool and append the Tool Messaage in the history\n",
    "                tool_msgs = self._execute_tool(tool_call)\n",
    "                chat_template = ChatPromptTemplate.from_messages(chat_template.messages + [tool_msgs])\n",
    "\n",
    "            # Reset for next round\n",
    "            tool_calls = {}\n",
    "            ai_msg = AIMessage(content=\"\")\n",
    "            for chunk in self.llm.stream(chat_template.messages):\n",
    "                if getattr(chunk, \"tool_call_chunks\", None):\n",
    "                    tool_calls = self._stream_tool_content_extraction(chunk, tool_calls)\n",
    "\n",
    "                if getattr(chunk, \"content\", None):\n",
    "                    ai_msg.content += chunk.content\n",
    "                    yield chunk.content\n",
    "\n",
    "    def _build_chat_template(self,\n",
    "                            message: Union[str, HumanMessage, ChatPromptTemplate]) -> ChatPromptTemplate:\n",
    "        \"\"\"\n",
    "        Construct a ChatPromptTemplate from a user message, prepending the system prompt.\n",
    "\n",
    "        Args:\n",
    "            message (Union[str, HumanMessage, ChatPromptTemplate]): The incoming message.\n",
    "\n",
    "        Returns:\n",
    "            ChatPromptTemplate: Combined system prompt and user message template.\n",
    "        \"\"\"\n",
    "        if isinstance(message, str):\n",
    "            user_msg = HumanMessage(content=message)\n",
    "            return ChatPromptTemplate.from_messages([self.system_prompt, user_msg])\n",
    "        \n",
    "        if isinstance(message, HumanMessage):\n",
    "            return ChatPromptTemplate.from_messages([self.system_prompt, message])\n",
    "        \n",
    "        if isinstance(message, ChatPromptTemplate):\n",
    "            # Avoid duplicating a system prompt if the caller already supplied one.\n",
    "            non_system: List[Any] = [m for m in message.messages if not isinstance(m, SystemMessage)]\n",
    "            chat_template = ChatPromptTemplate.from_messages([self.system_prompt, *non_system])\n",
    "            return ChatPromptTemplate(chat_template.format_messages())\n",
    "\n",
    "        raise TypeError(\n",
    "            \"message must be str, HumanMessage or ChatPromptTemplate, \"\n",
    "            f\"got {type(message).__name__}\"\n",
    "        )\n",
    "\n",
    "    def _is_tool_call(self, ai_message: AIMessage) -> bool:\n",
    "        \"\"\"\n",
    "        Determine if the AIMessage includes a tool call.\n",
    "\n",
    "        Args:\n",
    "            ai_message (AIMessage): The model's response message.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if there's at least one tool call, False otherwise.\n",
    "        \"\"\"\n",
    "        return bool(getattr(ai_message, \"tool_calls\", None))\n",
    "\n",
    "    def _execute_tool(self, call: Dict) -> ToolMessage:\n",
    "        \"\"\"\n",
    "        Execute a specified tool call and wrap the output in a ToolMessage.\n",
    "\n",
    "        Args:\n",
    "            call (Dict): A dict containing 'name', 'args', and 'id' for the tool call.\n",
    "\n",
    "        Returns:\n",
    "            ToolMessage: The tool invocation result.\n",
    "        \"\"\"    \n",
    "        result = self.tools[call['name']].invoke(call['args'])\n",
    "        return ToolMessage(content=result, tool_call_id=call['id'])\n",
    "\n",
    "    def _stream_tool_content_extraction(self, chunk: AIMessageChunk, tool_calls: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Accumulate streaming chunks of a tool call into a complete call structure.\n",
    "\n",
    "        Args:\n",
    "            chunk (AIMessageChunk): A chunk from the LLM containing tool call pieces.\n",
    "            tool_calls (Dict[int, Dict]): Existing partial tool call data indexed by chunk index.\n",
    "\n",
    "        Returns:\n",
    "            Dict[int, Dict]: Updated mapping of chunk index to complete tool call info.\n",
    "        \"\"\"\n",
    "        for tool_chunk in chunk.tool_call_chunks:\n",
    "            index = tool_chunk['index']\n",
    "            if index not in tool_calls:\n",
    "                tool_calls[index] = {\n",
    "                    'name': tool_chunk['name'],  # might be None at first\n",
    "                    'args': '',\n",
    "                    'id': tool_chunk['id']\n",
    "                }\n",
    "            if tool_chunk['name'] is not None:\n",
    "                tool_calls[index]['name'] = tool_chunk['name']\n",
    "            if tool_chunk['args']:\n",
    "                tool_calls[index]['args'] += tool_chunk['args']\n",
    "        return tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c782a9-119e-451b-828a-3e51f874a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'o3-mini'\n",
    "agent_name = 'ReAct Agent'\n",
    "\n",
    "llm = ChatOpenAI(model=model_name)\n",
    "\n",
    "GENERATION_SYSTEM_PROMPT = \"\"\"\n",
    "You are the {name}, an AI expert with specialized knowledge in Orthodox theology and historical context. Based on the user's inquiry and the provided summary, you will:\n",
    "\n",
    "- Deliver a thorough, clear, and logically reasoned response directly addressing the user's question.\n",
    "- Ground your answer firmly in the summarized material to ensure factual accuracy and coherence.\n",
    "- Never utilize your knowledge to supplement the response.\n",
    "- Use any citations that the summarized material provides. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c0dad2b8-8d68-4821-a932-9a11139846cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "import textwrap\n",
    "\n",
    "from crewai_tools import DallETool\n",
    "from crewai_tools import CodeInterpreterTool\n",
    "\n",
    "class ImageGenerationInput(BaseModel):\n",
    "    description: str = Field(..., description=\"A prompt that describes the image and will be passed to the Image Gen Model\")\n",
    "\n",
    "class ExecutesPythonCodeInput(BaseModel):\n",
    "    code: str = Field(..., description=\"The Python code to execute.\")\n",
    "    libraries: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"A list of Python libraries to install before execution.\",\n",
    "    )\n",
    "\n",
    "@tool(\"image_generation\", args_schema=ImageGenerationInput)\n",
    "def image_generation(description: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates an image using the CrewAI Dall-E Tool based on a text prompt.\n",
    "\n",
    "    Parameters:\n",
    "        description (str): A description of the scene to generate.\n",
    "\n",
    "    Returns:\n",
    "        str: A dictionary in string format with keys:\n",
    "            - 'image_url': URL of the generated image\n",
    "            - 'image_description': The full natural language scene description\n",
    "            - or an error message if generation fails\n",
    "    \"\"\"\n",
    "    dalle = DallETool()\n",
    "    \n",
    "    try:\n",
    "        response = dalle.run(image_description=description)\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@tool(\"executes_python_code\", args_schema=ExecutesPythonCodeInput)\n",
    "def executes_python_code(code: str, libraries: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Executes a Python code snippet inside the CrewAI CodeInterpreterTool environment.\n",
    "\n",
    "    This function allows running arbitrary Python code and optionally installs \n",
    "    libraries inside a secure containerized interpreter environment provided by CrewAI.\n",
    "\n",
    "    Args:\n",
    "        code (str): The Python code to execute.\n",
    "        libraries (List[str]): A list of Python libraries to install before execution (e.g., ['pandas', 'numpy']).\n",
    "\n",
    "    Returns:\n",
    "        str: The output or result of the executed code, or an error message if execution fails.\n",
    "    \"\"\"\n",
    "    # Dedent the code to prevent indentation errors\n",
    "    clean_code = textwrap.dedent(code)\n",
    "\n",
    "    # Initialize the interpreter tool\n",
    "    code_exec = CodeInterpreterTool()\n",
    "\n",
    "    # Run the code\n",
    "    try:\n",
    "        result = code_exec.run(code=clean_code, libraries_used=libraries)\n",
    "    except Exception as e:\n",
    "        result = f\"Execution failed with error: {e}\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "084b7b8a-a0b5-4392-b8a3-d2f182cb0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = {\n",
    "    executes_python_code.name: executes_python_code,\n",
    "    image_generation.name: image_generation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ab2b8f88eb88cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReAct_Agent(llm=llm, name=agent_name, system_prompt=GENERATION_SYSTEM_PROMPT, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cd381-de52-4185-8e53-105c06fd887b",
   "metadata": {},
   "source": [
    "* Simple responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7632f749-f603-4772-b616-04657a5a50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "message1 = 'Hello!'\n",
    "message2 = HumanMessage('Hello!')\n",
    "message3 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"human\",\n",
    "            'Hello!',\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "746e2d68-4bf5-499f-9c8b-5a9318601ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How may I assist you today with your questions on Orthodox theology or its historical context?'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(message1).messages[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "be95a29a-f7c5-442d-995b-cee5ff388510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you with your inquiry regarding Orthodox theology and its historical context today?'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(message2).messages[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "99aca50e-cf01-41d8-a612-d8039f20e099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today with your inquiry on Orthodox theology or historical context?'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(message3).messages[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "dc01d135-ad60-4486-af51-253b1d182565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today? Feel free to ask any questions you have regarding Orthodox theology or its historical context."
     ]
    }
   ],
   "source": [
    "for text in agent.stream(message1):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9462db38-4803-4c1b-aba3-2adedd7d33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today with questions or insights related to Orthodox theology or historical context?"
     ]
    }
   ],
   "source": [
    "for text in agent.stream(message2):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "255f9847-eb75-4219-8816-f77333fdee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "for text in agent.stream(message3):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa753ee9-d9ef-443a-b351-11620779e280",
   "metadata": {},
   "source": [
    "* Responses with tool execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "939ff16e-daa2-46a1-9919-50a5625371f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_REQUEST = (\n",
    "    \"Please use the image‑generation tool to create a 1024×1024 illustration of \"\n",
    "    \"a peaceful Orthodox monastery at sunrise, painted in classic icon style.\"\n",
    ")\n",
    "\n",
    "message1_tool = IMAGE_REQUEST\n",
    "\n",
    "message2_tool = HumanMessage(content=IMAGE_REQUEST)\n",
    "\n",
    "message3_tool = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", IMAGE_REQUEST),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6041c071-d9e8-438a-85ab-5c459017d48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Dall-E Tool\n"
     ]
    }
   ],
   "source": [
    "response1 = agent.invoke(message1_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "489ed73d-dd96-4b61-b358-2ca44632a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your requested illustration:\n",
      "\n",
      "A 1024×1024 depiction of a serene Orthodox monastery at sunrise. The illustration features traditional architectural elements of Orthodox monastic buildings, including domed roofs, intricate decorative details, and a peaceful overall layout. The soft, warm glow of the rising sun gently illuminates the scene, casting delicate shadows, and lending the image a contemplative and sacred ambiance. It captures the aesthetics of classical Orthodox iconography with rich, deep hues and touching golden accents that echo the transcendent spiritual themes found in pre-1912 sacred art. \n",
      "\n",
      "You can view the image using the following link:\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-H2PSqn2m6bLxgXgt13hGST4y.png?st=2025-04-18T21%3A16%3A00Z&se=2025-04-18T23%3A16%3A00Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=b1a0ae1f-618f-4548-84fd-8b16cacd5485&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-18T12%3A22%3A02Z&ske=2025-04-19T12%3A22%3A02Z&sks=b&skv=2024-08-04&sig=dTHbtaMuogGaQM8LklnXo0GJP1PRtKSrilZs9SX4pfk%3D\n",
      "\n",
      "By using such visuals, we can connect more deeply with the rich traditions and spiritual symbolism deeply embedded in Orthodox monastic and iconographic art. Enjoy the serene reflection of Orthodox heritage encapsulated in this illustration!\n"
     ]
    }
   ],
   "source": [
    "print(response1.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a463781a-a701-4534-a2e9-6e534fc1aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Dall-E Tool\n"
     ]
    }
   ],
   "source": [
    "response2 = agent.invoke(message2_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0fa22c64-4fa0-4013-bb90-9241ce093e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the generated illustration:\n",
      "\n",
      "A 1024×1024 image of a peaceful Orthodox monastery at sunrise, painted in classic icon style. The scene captures the serene beauty of the monastery with its traditional Byzantine architecture, complete with intricate detailing and golden accents. The soft light of the rising sun casts warm hues of gold, pink, and soft blue that envelop the domes and arches, creating an almost sacred glow evocative of classic Eastern Orthodox iconography. Enjoy this visual representation of spiritual tranquility and timeless beauty.\n"
     ]
    }
   ],
   "source": [
    "print(response2.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "56469017-05bd-43bf-830e-f98885b8becf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Dall-E Tool\n"
     ]
    }
   ],
   "source": [
    "response3 = agent.invoke(message3_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3d47ead5-e7f2-4d8a-8f45-ab29c5680fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the generated illustration:\n",
      "\n",
      "A 1024×1024 image of a peaceful Orthodox monastery at sunrise, painted in classic icon style. The scene captures the serene beauty of the monastery with its traditional Byzantine architecture, complete with intricate detailing and golden accents. The soft light of the rising sun casts warm hues of gold, pink, and soft blue that envelop the domes and arches, creating an almost sacred glow evocative of classic Eastern Orthodox iconography. Enjoy this visual representation of spiritual tranquility and timeless beauty.\n"
     ]
    }
   ],
   "source": [
    "print(response2.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "93307679-4fcd-4563-83c7-d4fab49f4d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Dall-E Tool\n",
      "Here is the generated image based on your detailed description. The illustrated scene shows a peaceful Orthodox monastery at sunrise, capturing the golden hues of dawn on ancient stone walls. Painted in a classic icon style, the image features gentle brush strokes and a subtle color palette that evoke a timeless spiritual serenity. You can view the image by accessing the following URL:\n",
      "\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-TO2mmVA1T0ptTCyvKnEqf2hv.png?st=2025-04-18T21%3A17%3A28Z&se=2025-04-18T23%3A17%3A28Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=b1a0ae1f-618f-4548-84fd-8b16cacd5485&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-18T22%3A17%3A28Z&ske=2025-04-19T22%3A17%3A28Z&sks=b&skv=2024-08-04&sig=VNyTSeUNJG6YYU50DIsC0IfpiAl%2B4L47cAa6rCVigjI%3D\n",
      "\n",
      "Feel free to use or share it as needed."
     ]
    }
   ],
   "source": [
    "for text in agent.stream(message1_tool):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1bfee4cf-2d48-4c02-acd7-b5382c9629d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Dall-E Tool\n",
      "Here is the illustration you requested:\n",
      "\n",
      "URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-3tgN8qg59BbYFXhi743w25fP.png?st=2025-04-18T21%3A17%3A57Z&se=2025-04-18T23%3A17%3A57Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=b1a0ae1f-618f-4548-84fd-8b16cacd5485&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-18T10%3A45%3A25Z&ske=2025-04-19T10%3A45%3A25Z&sks=b&skv=2024-08-04&sig=Y3%2BfB7xJaL7%2BsI6ri9KGHkqtwnsQkFDoa8NtDi7ARBI%3D\n",
      "\n",
      "This image depicts a peaceful Orthodox monastery at sunrise, rendered in the classic icon style. The serene composition includes traditional architectural features such as ornate domes and intricate religious iconography, all bathed in the golden glow of the early morning light. The style embraces the rich, bold colors, fine details, and spiritual ambiance characteristic of Byzantine iconography. Enjoy your image!"
     ]
    }
   ],
   "source": [
    "for text in agent.stream(message2_tool):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e150d7b1-3d0d-4560-b3cf-66f2c1cce670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Dall-E Tool\n",
      "Here is your illustration:\n",
      "\n",
      "Image Description: A 1024x1024 depiction of a serene Eastern Orthodox monastery bathed in the soft golden light of sunrise. Rendered in a classic icon style, the image features detailed architectural elements typical of Orthodox monasteries along with symbolic, stylized figures. The use of vibrant gold hues and gentle pastels creates a calm, spiritual atmosphere, evoking the historical and revered ambiance of a traditional monastic setting.\n",
      "\n",
      "You can view the image using the following link:\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-VAYCAx8TxgIltED5aOABbjXd.png?st=2025-04-18T21%3A18%3A19Z&se=2025-04-18T23%3A18%3A19Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=b1a0ae1f-618f-4548-84fd-8b16cacd5485&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-18T03%3A41%3A47Z&ske=2025-04-19T03%3A41%3A47Z&sks=b&skv=2024-08-04&sig=9Y2zW1/J8RAWZ5V3iNO%2BLUcnkYcamdGRpHCCibZT2m4%3D\n",
      "\n",
      "I hope this illustration meets your expectations and captures the desired peaceful and venerable spirit of the Orthodox monastic tradition."
     ]
    }
   ],
   "source": [
    "for text in agent.stream(message3_tool):\n",
    "    print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916fe2fc-7c26-4911-9120-d0a83cb15416",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Structured Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a59d7561-c367-40ba-b81d-943723a1fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "class Structured_Agent:\n",
    "    \n",
    "    def __init__(self,\n",
    "                name: str,\n",
    "                llm: Union[ChatOpenAI, ChatAnthropic],\n",
    "                system_prompt: str,\n",
    "                structure_response = None):\n",
    "        # Initialize basic attributes of the agent\n",
    "        self.name = name\n",
    "        self.llm = llm\n",
    "        self.system_prompt = SystemMessage(system_prompt.format(name=self.name))\n",
    "        self.structure_response = structure_response\n",
    "        \n",
    "        # Bind the llm with a structured output if passed\n",
    "        self.llm = self.llm.with_structured_output(self.structure_response) if self.structure_response else self.llm\n",
    "\n",
    "    def invoke(self, message: Union[str, HumanMessage, ChatPromptTemplate]):\n",
    "        chat_template = self._build_chat_template(message)\n",
    "        return self.llm.invoke(chat_template.messages)\n",
    "    \n",
    "    def stream(self, message: Union[str, HumanMessage, ChatPromptTemplate]):\n",
    "        return self.invoke(message)\n",
    "\n",
    "    def _build_chat_template(self,\n",
    "                            message: Union[str, HumanMessage, ChatPromptTemplate]) -> ChatPromptTemplate:\n",
    "        \"\"\"\n",
    "        Construct a ChatPromptTemplate from a user message, prepending the system prompt.\n",
    "\n",
    "        Args:\n",
    "            message (Union[str, HumanMessage, ChatPromptTemplate]): The incoming message.\n",
    "\n",
    "        Returns:\n",
    "            ChatPromptTemplate: Combined system prompt and user message template.\n",
    "        \"\"\"\n",
    "        if isinstance(message, str):\n",
    "            user_msg = HumanMessage(content=message)\n",
    "            return ChatPromptTemplate.from_messages([self.system_prompt, user_msg])\n",
    "        \n",
    "        if isinstance(message, HumanMessage):\n",
    "            return ChatPromptTemplate.from_messages([self.system_prompt, message])\n",
    "        \n",
    "        if isinstance(message, ChatPromptTemplate):\n",
    "            # Avoid duplicating a system prompt if the caller already supplied one.\n",
    "            non_system: List[Any] = [m for m in message.messages if not isinstance(m, SystemMessage)]\n",
    "            chat_template = ChatPromptTemplate.from_messages([self.system_prompt, *non_system])\n",
    "            return ChatPromptTemplate(chat_template.format_messages())\n",
    "\n",
    "        raise TypeError(\n",
    "            \"message must be str, HumanMessage or ChatPromptTemplate, \"\n",
    "            f\"got {type(message).__name__}\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "742a6ffb-8359-47df-ba23-1e958f5e44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class AnalyzerOutput(BaseModel):\n",
    "    is_religious: Literal[\"Religious\", \"Non-Religious\"] = Field(\n",
    "        ...,\n",
    "        description=\"True if the query relates explicitly to religious or theological matters of orthodox christianity, otherwise, False.\",\n",
    "    )\n",
    "    clarification_needed: bool = Field(\n",
    "        ...,\n",
    "        description=\"True if further clarification from the user is needed; otherwise, False.\",\n",
    "    )\n",
    "    clarification_instructions: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Specific instructions on what clarification is required from the user, if applicable.\",\n",
    "    )\n",
    "    key_topics: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",\n",
    "    )\n",
    "    context_requirements: str = Field(\n",
    "        ..., description=\"A clear explanation of the query's context needs\"\n",
    "    )\n",
    "    query_complexity: Literal[\"Low\", \"Medium\", \"High\"] = Field(\n",
    "        ..., description=\"'Low', 'Medium', or 'High' complexity\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        ...,\n",
    "        description=\"The Chain of Thought that has been done in order to analyze the user query\",\n",
    "    )\n",
    "\n",
    "ANALYZER_SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI assistant called {name}. Your role is to carefully examine the user's request, identify key components or sub-questions, clarify ambiguities, and outline the specific objectives for subsequent steps. \n",
    "When analyzing a query, consider:\n",
    "- The user's main goals or questions.\n",
    "- The context or domain, particularly Orthodox theology if relevant.\n",
    "- Any constraints or relevant details.\n",
    "Your output should guide how the system (and subsequent agents) will approach retrieval and reasoning.\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model='o3-mini')\n",
    "agent_name = 'Analyzer Agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2376a729-adfe-4374-8654-b66201b2b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Structured_Agent(llm=llm,\n",
    "                         system_prompt=ANALYZER_SYSTEM_PROMPT,\n",
    "                         structure_response=AnalyzerOutput,\n",
    "                         name=agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "22f25161-017f-4746-8a66-fdf94d0f5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_prompt = \"Why do Orthodox Christians venerate icons, and how did that practice develop historically?\"\n",
    "human_prompt = HumanMessage(content=\"Please outline the key differences between Orthodox and Roman‑Catholic fasting traditions, and explain their theological rationale.\")\n",
    "chat_tmpl = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"Is the Filioque still the main point of dispute between East and West?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ad522c99-4e5e-4f5e-a75f-0f24a0d39d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(is_religious='Religious', clarification_needed=False, clarification_instructions=None, key_topics=['Orthodox Christianity', 'Icons', 'Icon Veneration', 'Theology', 'Historical Development'], context_requirements='The query requests an explanation of the theological basis for the veneration of icons in Orthodox Christianity as well as a historical overview of how the practice developed. It requires discussing both doctrinal and historical aspects, including events like the Iconoclastic Controversy.', query_complexity='Medium', reasoning='The question contains two primary components: the rationale behind the veneration of icons and the developmental history of the practice within Orthodox Christianity. The response should detail the theological reasons (e.g., the incarnation and the role of icons as windows to the divine) while also outlining the historical evolution including significant events like the Iconoclastic Controversy and its eventual resolution in favor of icon veneration.')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(str_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ace0d53d-b023-4ef2-8dbe-05c65059b383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(is_religious='Religious', clarification_needed=False, clarification_instructions=None, key_topics=['Orthodox fasting traditions', 'Roman‑Catholic fasting traditions', 'Theological rationale', 'Liturgical practice', 'Spiritual discipline', 'Ecclesiology'], context_requirements='The query seeks a comparative analysis of the fasting customs in Eastern Orthodox and Roman‑Catholic traditions along with an explanation of the underlying theological justifications for such practices. This requires explaining both the practical differences (e.g., fasting days, types of dietary restrictions, seasons of observance) and the spiritual or doctrinal reasons that inform these customs.', query_complexity='Medium', reasoning='The query asks for an outline of the key differences between the fasting traditions in the Orthodox and Roman‑Catholic churches and an explanation of the theological rationale behind these practices. The answer should include specifics about how each tradition delineates fasting periods (such as the stricter fasting rules during Great Lent and other fasting periods in the Orthodox Church, compared to the more relaxed or differently structured fasting rules in the Roman‑Catholic Church), what types of foods are restricted, and why these practices are maintained in each tradition from a theological perspective. In Orthodox theology, fasting is closely tied to asceticism, spiritual purification, and participation in the liturgical cycle, often involving abstinence from meat, dairy, and other animal products on designated days. In contrast, Roman‑Catholic fasting rules have evolved over time, often emphasizing penance and self-discipline while being less rigorous than Orthodox practices. The theological rationale in both cases centers on imitating Christ’s own fasting and sacrifice, personal sanctification, and preparation for significant feasts, but each tradition contextualizes these goals within its own liturgical, historical, and ecclesiological frameworks.')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(human_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "254cee9a-d244-4fa1-b3b4-835a6ecc41a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(is_religious='Religious', clarification_needed=False, clarification_instructions=None, key_topics=['Filioque', 'Eastern Orthodox theology', 'Western Christianity', 'ecumenical disputes', 'theological controversy'], context_requirements='The query addresses an important historical and theological dispute within Christianity concerning the Filioque clause. It assumes familiarity with the historical context and theological nuances of the East-West schism, particularly within Orthodox and Roman Catholic traditions.', query_complexity='Medium', reasoning='The query is explicitly about a theological dispute—whether the inclusion of the Filioque clause in the Nicene Creed remains the primary point of contention between Eastern Orthodox and Western Christianity. Key points to consider include the historical evolution of the controversy, the role of the Filioque in separating the two traditions, and whether current dialogues have shifted focus onto other issues. The question is inherently religious and touches on orthodox Christian theology and ecumenical relations, which qualifies it as a medium complexity query.')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(chat_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fc494d00-9895-4e29-9fc8-6ec152ba1ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(is_religious='Religious', clarification_needed=False, clarification_instructions=None, key_topics=['Orthodox Christianity', 'icon veneration', 'theology', 'historical development', 'iconoclastic controversy'], context_requirements='The question involves an explanation of the theological reasoning behind the veneration of icons in Orthodox Christianity as well as a historical overview of how this practice developed over time, including key events such as the Iconoclastic Controversy.', query_complexity='Medium', reasoning='The query asks for an explanation of both the theological basis and historical evolution of the practice of venerating icons within Orthodox Christianity. This involves discussing why icons are considered important--as representations that allow believers to venerate and connect with holy figures without being objects of worship themselves--and providing historical context, such as the development of early Christian art, the theological justifications that arose, and the challenges presented by the Iconoclastic Controversy which eventually solidified the tradition.')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.stream(str_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "26156fb1-480b-4812-9706-8f692723c469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(is_religious='Religious', clarification_needed=False, clarification_instructions=None, key_topics=['Orthodox fasting traditions', 'Roman‑Catholic fasting traditions', 'theological rationale', 'fasting guidelines', 'spiritual discipline', 'penance'], context_requirements='The answer should compare and contrast the fasting practices of the Eastern Orthodox Church and the Roman‑Catholic Church. It should detail the specific fasting regulations (such as the number and strictness of fasting periods, permitted and prohibited foods, and liturgical contexts) while explaining the underlying theological reasoning behind these practices in each tradition.', query_complexity='Medium', reasoning='The query asks for an outline of the key differences between Orthodox and Roman‑Catholic fasting traditions and an explanation of their theological rationale. This involves identifying the specific fasting practices and rules in each tradition (e.g., the frequency of fasts, types of foods allowed or restricted, and liturgical significance) as well as analyzing the theological underpinnings (such as ideas about penance, spiritual discipline, participation in Christ’s suffering, and the nature of ascetic practices). The analysis should be clear and comparative, offering insights into how each tradition’s understanding of fasting shapes its liturgical life and spiritual practices.')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.stream(human_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "137ea8cf-62eb-42d6-b8f7-42973678ed80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(is_religious='Religious', clarification_needed=False, clarification_instructions=None, key_topics=['Filioque', 'East-West Schism', 'Theology', 'Christian Doctrine', 'Orthodox-Christian Relations'], context_requirements='The query relates to theological disputes between Eastern Orthodox and Western (primarily Roman Catholic) traditions, specifically about the Filioque clause in the Nicene Creed. Context around historical debates and theological implications is relevant.', query_complexity='Medium', reasoning='The question asks if the Filioque remains the main point of dispute between East and West. It is clearly a theological inquiry concerning the doctrinal differences related to the procession of the Holy Spirit in Christianity. The analysis required identification of the key issue (the Filioque controversy) and its significance in the context of ongoing ecclesiastical differences, especially between the Orthodox and Catholic churches.')"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.stream(chat_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00ea6c-419c-4df9-977b-eeccf8c07cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93866726-a955-4ef5-978d-797d759d756c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
