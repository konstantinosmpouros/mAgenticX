{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f594c1ba-ca36-46e8-8789-8df62851f3c7",
   "metadata": {},
   "source": [
    "# OrthodoxAI - Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd36b1-71ca-4bd8-9e69-99206f25b0e4",
   "metadata": {},
   "source": [
    "> Konstantinos Mpouros <br>\n",
    "> Github: https://github.com/konstantinosmpouros?tab=repositories<br>\n",
    "> Year: 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8e8053-ccff-461b-9a96-8f44526620b1",
   "metadata": {},
   "source": [
    "## About the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b5c23-4989-4a01-a419-bfb4628abcba",
   "metadata": {},
   "source": [
    "This notebook is dedicated to prototyping and testing the behavior of individual and collaborative agents within the **OrthodoxAI** multi-agent system.\n",
    "\n",
    "It serves as a sandbox to:\n",
    "\n",
    "- Define agent roles (e.g., Reflection, Generator, Summarizer)\n",
    "- Simulate agent communication structure patters\n",
    "- Experiment with routing logic and agent chaining (without LangGraph)\n",
    "- Test prompt templates and output formatting for each agent\n",
    "- Evaluate performance and consistency across multiple LLM-backed tasks\n",
    "\n",
    "This notebook is used for isolated debugging and experimentation before integrating agents into the main production pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713835e-2b12-4806-b6c9-e771fed71705",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3edff7-c5f4-475b-93fa-94ab5882f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API Keys\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8e99c-6ea1-4992-a245-a1aae18bc630",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## OpenAI APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e6840-8369-42bb-b8d5-d898ef9bbfe7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Client Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd1076-2f94-49d4-8e08-ccbe70da8fd4",
   "metadata": {},
   "source": [
    "* Import libraries to chat with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551f9895-c065-4ddf-8390-a248bac20927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc06a6-cd92-42b1-a0c3-93a71003f565",
   "metadata": {},
   "source": [
    "* Define a Structured Output template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85a9871-35f4-44d1-b215-7618bd4d86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzerOutput(BaseModel):\n",
    "    classification: Literal[\"Religious\", \"Non-Religious\"] = Field(..., description=\"Either 'Religious' or 'Non-Religious'\")\n",
    "    key_topics: List[str] = Field(..., description=\"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",)\n",
    "    context_requirements: str = Field(..., description=\"A clear explanation of the query's context needs\")\n",
    "    query_complexity: Literal[\"Low\", \"Medium\", \"High\"] = Field(..., description=\"'Low', 'Medium', or 'High' complexity\")\n",
    "    reasoning: str = Field(..., description=\"The Chain of Thought that has been done in order to analyze the user query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ecee3e-adc7-49a8-b31e-b4a70ae0d995",
   "metadata": {},
   "source": [
    "* Initialize configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01b20ef-1bac-48d3-87b7-ba82518909ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'o3-mini'\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "chat_template = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant that classifies user queries as either religious or non-religious and extracts key topics.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Helloo!!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df3561-9013-418f-8a31-448bfc45bb4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Simple response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af41ee06-48d0-47dc-b860-4463cd0773e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "Key Topics: Greeting\n",
      "\n",
      "The query \"Helloo!!\" appears to be a friendly greeting with no religious content.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME, \n",
    "    messages=chat_template,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1e8da6-c71b-4d70-9f65-c5cdc649abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key Topic:\n",
      "• Greeting\n",
      "\n",
      "The user’s message appears to be a simple, informal greeting without any religious context.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=chat_template\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4541d-fe4c-409a-b7d1-372ed5cdfd8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Streaming response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f5344f-dc43-44ce-97ce-fb44b1ff8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key Topics: Greeting\n",
      "\n",
      "The message appears to be a friendly, informal greeting with no religious content."
     ]
    }
   ],
   "source": [
    "response = \"\"\n",
    "\n",
    "for chunk in client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=chat_template,\n",
    "    stream=True\n",
    "):\n",
    "    \n",
    "    if not chunk.choices:\n",
    "        continue  # Just a safeguard\n",
    "    \n",
    "    # The partial text is in 'delta.content'\n",
    "    chunk_text = chunk.choices[0].delta.content\n",
    "    if chunk_text is None:\n",
    "        continue\n",
    "\n",
    "    response += chunk_text\n",
    "    print(chunk_text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "115f69cc-b56e-4b7b-a606-6e35befe5496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key Topics: Greeting, informal salutation."
     ]
    }
   ],
   "source": [
    "stream = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=chat_template,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == 'response.refusal.delta':\n",
    "        print(event.delta, end=\"\")\n",
    "    elif event.type == 'response.output_text.delta':\n",
    "        print(event.delta, end=\"\")\n",
    "    elif event.type == 'response.error':\n",
    "        print(event.error, end=\"\")\n",
    "    elif event.type == 'response.completed':\n",
    "        response = event.response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ed8558-2b84-4dad-a86a-e722b8369fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_67eefa37c2048191b2860f006b1d9261003da8076e6768b6', summary=[], type='reasoning', status=None),\n",
       " ResponseOutputMessage(id='msg_67eefa381b208191931e99bd52493d89003da8076e6768b6', content=[ResponseOutputText(annotations=[], text='Classification: Non-religious\\n\\nKey Topics: Greeting, informal salutation.', type='output_text')], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654bc96-f254-4c71-a12e-e3e1600e049d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Structured response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8847254-15cd-4ee6-84f8-8b05c16e8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.chat.completions.parse(\n",
    "    model=MODEL_NAME,\n",
    "    messages=chat_template,\n",
    "    response_format=AnalyzerOutput\n",
    ")\n",
    "\n",
    "structured_object = response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d149aba4-67ce-4565-9e6a-e14c2d80bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(classification='Non-Religious', key_topics=['greeting'], context_requirements='No complexity is involved and there is no religious context present in the query. The query is simply a casual greeting.', query_complexity='Low', reasoning=\"The query 'Helloo!!' is a casual greeting with no mention of religious topics, symbols, or language. There is no indication of the conversation touching on religious themes, hence it is classified as non-religious and of low complexity.\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da3d419d-77cf-4978-b991-2f1822d5dd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\\n    \"greeting\"\\n  ],\\n  \"context_requirements\": \"No complexity is involved and there is no religious context present in the query. The query is simply a casual greeting.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The query \\'Helloo!!\\' is a casual greeting with no mention of religious topics, symbols, or language. There is no indication of the conversation touching on religious themes, hence it is classified as non-religious and of low complexity.\"\\n}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab4decd-6228-4d30-bb82-5a68537989c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "assistant\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.function_call)\n",
    "print(response.choices[0].message.tool_calls)\n",
    "print(response.choices[0].message.role)\n",
    "print(response.choices[0].message.refusal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "177fa1c9-4953-4dab-a5ac-a80a4d865546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4511/789635851.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  schema_dict = AnalyzerOutput.schema()\n"
     ]
    }
   ],
   "source": [
    "schema_dict = AnalyzerOutput.schema()\n",
    "schema_dict[\"additionalProperties\"] = False\n",
    "text_dict = {\n",
    "    \"format\": {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"name\": \"MyAnalyzerOutput\",  # arbitrary name\n",
    "        \"strict\": True,\n",
    "        \"schema\": schema_dict\n",
    "    }\n",
    "}\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=chat_template,\n",
    "    text=text_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653f33e6-dfb9-415f-a903-42979b5e6d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_67eefa3c1c608191a232cc4cc3cc9aa505b562a8227eead7', created_at=1743714876.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='o3-mini-2025-01-31', object='response', output=[ResponseReasoningItem(id='rs_67eefa3e69908191a96199dec3343ce505b562a8227eead7', summary=[], type='reasoning', status=None), ResponseOutputMessage(id='msg_67eefa3f67788191b6a07580c38dfaf905b562a8227eead7', content=[ResponseOutputText(annotations=[], text='{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\\n    \"greeting\"\\n  ],\\n  \"context_requirements\": \"The query is simply a casual greeting without any religious content or additional context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user message \\'Helloo!!\\' is a greeting and does not contain any content related to religious topics. Therefore, it is classified as non-religious with the key topic being a greeting.\"\\n}', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort='medium', generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatTextJSONSchemaConfig(name='MyAnalyzerOutput', schema_={'properties': {'classification': {'description': \"Either 'Religious' or 'Non-Religious'\", 'enum': ['Religious', 'Non-Religious'], 'title': 'Classification', 'type': 'string'}, 'key_topics': {'description': \"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\", 'items': {'type': 'string'}, 'title': 'Key Topics', 'type': 'array'}, 'context_requirements': {'description': \"A clear explanation of the query's context needs\", 'title': 'Context Requirements', 'type': 'string'}, 'query_complexity': {'description': \"'Low', 'Medium', or 'High' complexity\", 'enum': ['Low', 'Medium', 'High'], 'title': 'Query Complexity', 'type': 'string'}, 'reasoning': {'description': 'The Chain of Thought that has been done in order to analyze the user query', 'title': 'Reasoning', 'type': 'string'}}, 'required': ['classification', 'key_topics', 'context_requirements', 'query_complexity', 'reasoning'], 'title': 'AnalyzerOutput', 'type': 'object', 'additionalProperties': False}, type='json_schema', description=None, strict=True)), truncation='disabled', usage=ResponseUsage(input_tokens=36, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=423, output_tokens_details=OutputTokensDetails(reasoning_tokens=320), total_tokens=459), user=None, store=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024a7455-55d7-4d79-8cd0-0b3a442a53d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\\n    \"greeting\"\\n  ],\\n  \"context_requirements\": \"The query is simply a casual greeting without any religious content or additional context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user message \\'Helloo!!\\' is a greeting and does not contain any content related to religious topics. Therefore, it is classified as non-religious with the key topic being a greeting.\"\\n}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e0e4a8-ef99-43bd-802e-7c33047bfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseOutputText(annotations=[], text='{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\\n    \"greeting\"\\n  ],\\n  \"context_requirements\": \"The query is simply a casual greeting without any religious content or additional context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user message \\'Helloo!!\\' is a greeting and does not contain any content related to religious topics. Therefore, it is classified as non-religious with the key topic being a greeting.\"\\n}', type='output_text')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[1].content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a8341-3e6a-49e0-8132-ff89f9bd013c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multi-Step Structured Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5da65-0d59-4bf3-b8b4-8dca74ecd863",
   "metadata": {},
   "source": [
    "* Initialize the main template and the step's template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff2cc0c8-b610-4b71-a904-e15cca88be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5b53ab7-5af6-41b9-8fa4-8cac66d0b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
    "    ],\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a86bea6-3f00-4e0e-ae3b-40758b17a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_reasoning.refusal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de96d67d-7a44-4f1a-b023-786f1f50cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathReasoning(steps=[Step(explanation=\"The equation given is 8x + 7 = -23. We want to isolate the variable x. To do this, start by removing the constant term on the left side of the equation, which is 7. We'll do this by subtracting 7 from both sides of the equation.\", output='8x + 7 - 7 = -23 - 7'), Step(explanation='Subtracting 7 from both sides simplifies the equation. The left side becomes 8x, and the right side becomes -23 - 7, which is -30.', output='8x = -30'), Step(explanation='Now, we need to solve for x by isolating it. Since x is multiplied by 8, we do the opposite operation, which is dividing by 8, on both sides of the equation.', output='x = -30 / 8'), Step(explanation='Simplify the right side of the equation by performing the division. -30 divided by 8 simplifies to -3.75.', output='x = -3.75')], final_answer='x = -3.75')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "691a9dbd-f520-46c7-87af-7e0692718cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x = -3.75'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.parsed.final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49cead43-2452-412b-9276-0928e6a22ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Step(explanation=\"The equation given is 8x + 7 = -23. We want to isolate the variable x. To do this, start by removing the constant term on the left side of the equation, which is 7. We'll do this by subtracting 7 from both sides of the equation.\", output='8x + 7 - 7 = -23 - 7'),\n",
       " Step(explanation='Subtracting 7 from both sides simplifies the equation. The left side becomes 8x, and the right side becomes -23 - 7, which is -30.', output='8x = -30'),\n",
       " Step(explanation='Now, we need to solve for x by isolating it. Since x is multiplied by 8, we do the opposite operation, which is dividing by 8, on both sides of the equation.', output='x = -30 / 8'),\n",
       " Step(explanation='Simplify the right side of the equation by performing the division. -30 divided by 8 simplifies to -3.75.', output='x = -3.75')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.parsed.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0556a1-d37a-4656-9149-dd13d9347b81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Streaming Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c601a5d8-100d-4c91-8ba2-82a9e42c9a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4511/1884170164.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  schema_dict = AnalyzerOutput.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'classification': {'description': \"Either 'Religious' or 'Non-Religious'\",\n",
       "   'enum': ['Religious', 'Non-Religious'],\n",
       "   'title': 'Classification',\n",
       "   'type': 'string'},\n",
       "  'key_topics': {'description': \"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Key Topics',\n",
       "   'type': 'array'},\n",
       "  'context_requirements': {'description': \"A clear explanation of the query's context needs\",\n",
       "   'title': 'Context Requirements',\n",
       "   'type': 'string'},\n",
       "  'query_complexity': {'description': \"'Low', 'Medium', or 'High' complexity\",\n",
       "   'enum': ['Low', 'Medium', 'High'],\n",
       "   'title': 'Query Complexity',\n",
       "   'type': 'string'},\n",
       "  'reasoning': {'description': 'The Chain of Thought that has been done in order to analyze the user query',\n",
       "   'title': 'Reasoning',\n",
       "   'type': 'string'}},\n",
       " 'required': ['classification',\n",
       "  'key_topics',\n",
       "  'context_requirements',\n",
       "  'query_complexity',\n",
       "  'reasoning'],\n",
       " 'title': 'AnalyzerOutput',\n",
       " 'type': 'object',\n",
       " 'additionalProperties': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dict = AnalyzerOutput.schema()\n",
    "schema_dict[\"additionalProperties\"] = False\n",
    "schema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a390035-dbc1-45e8-9126-2f0385c5df4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': {'type': 'json_schema',\n",
       "  'name': 'MyAnalyzerOutput',\n",
       "  'schema': {'properties': {'classification': {'description': \"Either 'Religious' or 'Non-Religious'\",\n",
       "     'enum': ['Religious', 'Non-Religious'],\n",
       "     'title': 'Classification',\n",
       "     'type': 'string'},\n",
       "    'key_topics': {'description': \"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",\n",
       "     'items': {'type': 'string'},\n",
       "     'title': 'Key Topics',\n",
       "     'type': 'array'},\n",
       "    'context_requirements': {'description': \"A clear explanation of the query's context needs\",\n",
       "     'title': 'Context Requirements',\n",
       "     'type': 'string'},\n",
       "    'query_complexity': {'description': \"'Low', 'Medium', or 'High' complexity\",\n",
       "     'enum': ['Low', 'Medium', 'High'],\n",
       "     'title': 'Query Complexity',\n",
       "     'type': 'string'},\n",
       "    'reasoning': {'description': 'The Chain of Thought that has been done in order to analyze the user query',\n",
       "     'title': 'Reasoning',\n",
       "     'type': 'string'}},\n",
       "   'required': ['classification',\n",
       "    'key_topics',\n",
       "    'context_requirements',\n",
       "    'query_complexity',\n",
       "    'reasoning'],\n",
       "   'title': 'AnalyzerOutput',\n",
       "   'type': 'object',\n",
       "   'additionalProperties': False}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dict = {\n",
    "    \"format\": {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"name\": \"MyAnalyzerOutput\",  # arbitrary name\n",
    "        \"schema\": schema_dict\n",
    "    }\n",
    "}\n",
    "text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c74ceafa-f617-4147-8b98-e48d99c9cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"classification\": \"Non-Religious\",\n",
      "  \"key_topics\": [\"greeting\"],\n",
      "  \"context_requirements\": \"The query is a simple greeting message and does not imply any religious context.\",\n",
      "  \"query_complexity\": \"Low\",\n",
      "  \"reasoning\": \"The user's message 'Helloo!!' is a casual greeting without any religious elements. It falls under non-religious content, and the simplicity of the greeting means that the query is of low complexity.\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "stream = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=chat_template,\n",
    "    text=text_dict,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == 'response.refusal.delta':\n",
    "        print(event.delta, end=\"\")\n",
    "    elif event.type == 'response.output_text.delta':\n",
    "        print(event.delta, end=\"\")\n",
    "    elif event.type == 'response.error':\n",
    "        print(event.error, end=\"\")\n",
    "    elif event.type == 'response.completed':\n",
    "        response = event.response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3bf56d0-8171-4eef-8dce-86d2e8ae140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_67eefa4a0c588191a0db7699d16846980f551bba5511bb39', summary=[], type='reasoning', status=None),\n",
       " ResponseOutputMessage(id='msg_67eefa4acbec8191bedd9651ad84bf120f551bba5511bb39', content=[ResponseOutputText(annotations=[], text='{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\"greeting\"],\\n  \"context_requirements\": \"The query is a simple greeting message and does not imply any religious context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user\\'s message \\'Helloo!!\\' is a casual greeting without any religious elements. It falls under non-religious content, and the simplicity of the greeting means that the query is of low complexity.\"\\n}', type='output_text')], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee181dc1-467c-43b0-8eeb-b6343b9a17e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseReasoningItem(id='rs_67eefa4a0c588191a0db7699d16846980f551bba5511bb39', summary=[], type='reasoning', status=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6c17a89-fa55-4967-9943-6683422c2dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseOutputMessage(id='msg_67eefa4acbec8191bedd9651ad84bf120f551bba5511bb39', content=[ResponseOutputText(annotations=[], text='{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\"greeting\"],\\n  \"context_requirements\": \"The query is a simple greeting message and does not imply any religious context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user\\'s message \\'Helloo!!\\' is a casual greeting without any religious elements. It falls under non-religious content, and the simplicity of the greeting means that the query is of low complexity.\"\\n}', type='output_text')], role='assistant', status='completed', type='message')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fff3f5ad-e1d0-4352-95c0-4217e948e298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assistant'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1].role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b2d3fb2-d046-42f9-aa24-7fb13c9b2acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1].status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d51a2ac-8476-42b2-9c9e-e7a0c58ab15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"classification\": \"Non-Religious\",\\n  \"key_topics\": [\"greeting\"],\\n  \"context_requirements\": \"The query is a simple greeting message and does not imply any religious context.\",\\n  \"query_complexity\": \"Low\",\\n  \"reasoning\": \"The user\\'s message \\'Helloo!!\\' is a casual greeting without any religious elements. It falls under non-religious content, and the simplicity of the greeting means that the query is of low complexity.\"\\n}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[1].content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac5aa6-2fca-466b-ba02-e7a19cc67ff6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Function Calling Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6b3d08e-fbe7-432c-9a01-39b01476a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for a given location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"City and country e.g. Bogotá, Colombia\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"location\"\n",
    "        ],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "707735f0-5fb3-4e41-bf61-4f11c242fafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_67eefa4c1c1c81918cf2ded63d178ee201399e5e5dcbafd3', created_at=1743714892.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='o3-mini-2025-01-31', object='response', output=[ResponseReasoningItem(id='rs_67eefa4cffb48191a0ad2433af706f7f01399e5e5dcbafd3', summary=[], type='reasoning', status=None), ResponseFunctionToolCall(arguments='{\"location\": \"Paris, France\"}', call_id='call_StVkKwib4bjRUbJtum2aip1G', name='get_weather', type='function_call', id='fc_67eefa4d79208191918dac892115886a01399e5e5dcbafd3', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='get_weather', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'City and country e.g. Bogotá, Colombia'}}, 'required': ['location'], 'additionalProperties': False}, strict=True, type='function', description='Get current temperature for a given location.')], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort='medium', generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=68, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=79, output_tokens_details=OutputTokensDetails(reasoning_tokens=64), total_tokens=147), user=None, store=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=[{\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"}],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3ea1eb3-3bb6-4cfc-b853-96e8dd33fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"location\": \"Paris, France\"}\n",
      "fc_67eefa4d79208191918dac892115886a01399e5e5dcbafd3\n",
      "function_call\n",
      "get_weather\n"
     ]
    }
   ],
   "source": [
    "print(response.output[1].arguments)\n",
    "print(response.output[1].id)\n",
    "print(response.output[1].type)\n",
    "print(response.output[1].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d1e56-5f44-44f9-be10-163b705fb49d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Langchain LLM-Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815d4fd-cf6a-42c5-a725-5e44588c9776",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Langchain Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3005a-f51e-46c3-a4dd-714db9780330",
   "metadata": {},
   "source": [
    "* Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d8e3be1-c962-4c26-94da-b17f9614b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de0eab-146f-472d-8e49-4b28607e85ce",
   "metadata": {},
   "source": [
    "* Initialize Structure Output template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fe51cb6-2a8b-4674-b2fb-70ae9485e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzerOutput(BaseModel):\n",
    "    classification: Literal[\"Religious\", \"Non-Religious\"] = Field(..., description=\"Either 'Religious' or 'Non-Religious'\")\n",
    "    key_topics: List[str] = Field(..., description=\"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",)\n",
    "    context_requirements: str = Field(..., description=\"A clear explanation of the query's context needs\")\n",
    "    query_complexity: Literal[\"Low\", \"Medium\", \"High\"] = Field(..., description=\"'Low', 'Medium', or 'High' complexity\")\n",
    "    reasoning: str = Field(..., description=\"The Chain of Thought that has been done in order to analyze the user query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb277a-24e3-4b68-bc13-c8ae97fe2cd0",
   "metadata": {},
   "source": [
    "* Initialize configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03468a9e-0573-4c74-9e5c-99ec4fa411a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'o3-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ca3cd-1d5b-4842-b59e-cf4c410d03ee",
   "metadata": {},
   "source": [
    "* Initialize prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "384cd3ee-af74-4dd9-a466-9535575be0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant that classifies user queries as either religious or non-religious and extracts key topics.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Classify the following query and extract key concepts:\\n\\nQuery: {query}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant named {assistant_name}. Use the available tools to provide accurate information.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{user_input}\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c2c40-cabe-4dce-a754-1f1a907488ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41f9c072-bb06-41b0-a103-018928ea1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=MODEL_NAME)\n",
    "analyzer_chain = analyzer_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a934264-dc7d-48f2-8d40-d96c0f67bfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Classification: Non-religious\\n\\nKey Concepts:\\n• Greeting\\n• Salutation\\n• Casual communication', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 46, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_617f206dd9', 'finish_reason': 'stop', 'logprobs': None}, id='run-490abbfa-d40a-4703-9ec2-8adba68e51f3-0', usage_metadata={'input_tokens': 46, 'output_tokens': 95, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = analyzer_chain.invoke('Hello')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ab1aefe-e570-49f7-8fa9-a7a1eb6447bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key Concepts:\n",
      "• Greeting\n",
      "• Salutation\n",
      "• Casual communication \n",
      "\n",
      "\n",
      "{'token_usage': {'completion_tokens': 95, 'prompt_tokens': 46, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_617f206dd9', 'finish_reason': 'stop', 'logprobs': None} \n",
      "\n",
      "\n",
      "run-490abbfa-d40a-4703-9ec2-8adba68e51f3-0 \n",
      "\n",
      "\n",
      "{'input_tokens': 46, 'output_tokens': 95, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}\n"
     ]
    }
   ],
   "source": [
    "print(text.content, '\\n\\n')\n",
    "print(text.response_metadata, '\\n\\n')\n",
    "print(text.id, '\\n\\n')\n",
    "print(text.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944ffa9-e6af-4b1c-9d01-635950bcdabe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Simple Response & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "877a5ab3-a601-4e17-b496-c0292c35f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Fetches the current weather for a specified location.\"\"\"\n",
    "    # Placeholder implementation\n",
    "    return f\"The current weather in {location} is sunny with a temperature of 25°C.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f41bf7e-f734-4608-a594-0ac14dd33664",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=MODEL_NAME)\n",
    "llm_with_tools = llm.bind_tools([get_weather])\n",
    "chain = chat_prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bf12e66-23d6-4013-b5f3-fd970724160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's the weather in Thessaloniki?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2df8ccf-4bad-499b-a2f8-9a5f0ebe0c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5Yjq1KeYue0cxQuwukbArHuA', 'function': {'arguments': '{\"location\": \"Thessaloniki\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 75, 'total_tokens': 101, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_617f206dd9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e142ac56-65a0-4552-931a-63174a671c93-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Thessaloniki'}, 'id': 'call_5Yjq1KeYue0cxQuwukbArHuA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 75, 'output_tokens': 26, 'total_tokens': 101, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36e75e76-5cce-4b63-82ab-4e468eed46d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'location': 'Thessaloniki'},\n",
       "  'id': 'call_5Yjq1KeYue0cxQuwukbArHuA',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f4f0522-431f-403d-8d88-706046e0d4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51c9913c-4610-400f-aada-a20b8cff6608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tool_calls'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata['finish_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79a43f15-5dc1-4d2b-8fdf-858157ca25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's your name?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb61071f-db4a-4df5-9124-8f3bc741d235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My name is Athena. How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 71, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_617f206dd9', 'finish_reason': 'stop', 'logprobs': None}, id='run-31e4471d-30ed-4ca9-b894-ff339e3e3ce7-0', usage_metadata={'input_tokens': 71, 'output_tokens': 88, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d2a4c9b-1b7a-4b06-b4ee-0eee6ed2c559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f558201-7e20-4998-a947-f0d2ba51eecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Athena. How can I help you today?'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b52806b6-e96b-47d2-aaa7-496dddca93a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stop'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata['finish_reason']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a803e-2f5d-4d39-95f0-b474efed49f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Streaming Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dbe4b66-4cc2-4f28-be86-3b27561bdb0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=MODEL_NAME, streaming=True)\n",
    "analyzer_chain = analyzer_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76b0d784-c7ba-456d-b058-63800a9c5646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Non-religious\n",
      "\n",
      "Key topics: Greeting, Salutation\n",
      "\n",
      "The query \"Hello!!\" is a casual greeting and does not contain any religious content."
     ]
    }
   ],
   "source": [
    "response = ''\n",
    "for token in analyzer_chain.stream('Hello!!'):\n",
    "    response += token.content\n",
    "    print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cf68537-5358-4293-9cda-e45d98e68137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Classification: Non-religious\\n\\nKey topics: Greeting, Salutation\\n\\nThe query \"Hello!!\" is a casual greeting and does not contain any religious content.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e9893-d7ba-4724-9d4f-dcce243f8be1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Streaming Response & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8bee014-770b-4223-b52d-eb05eb813c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Fetches the current weather for a specified location.\"\"\"\n",
    "    # Placeholder implementation\n",
    "    return f\"The current weather in {location} is sunny with a temperature of 25°C.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c74110c8-af4d-4a2f-b79f-7093d441623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=MODEL_NAME, streaming=True)\n",
    "llm_with_tools = llm.bind_tools([get_weather])\n",
    "chain = chat_prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29248a6c-8ffe-41e5-98bd-e2d6b4bd03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's your name?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22eed1a5-8926-400f-a55d-3e7af0ca64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_content(chunk, tool_calls):\n",
    "    if chunk.tool_call_chunks:\n",
    "        for tool_chunk in chunk.tool_call_chunks:\n",
    "            index = tool_chunk['index']\n",
    "            if index not in tool_calls:\n",
    "                tool_calls[index] = {\n",
    "                    'name': tool_chunk['name'],  # might be None at first\n",
    "                    'args': '',\n",
    "                    'id': tool_chunk['id']\n",
    "                }\n",
    "            if tool_chunk['name'] is not None:\n",
    "                tool_calls[index]['name'] = tool_chunk['name']\n",
    "            if tool_chunk['args']:\n",
    "                tool_calls[index]['args'] += tool_chunk['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac2f3e70-08e8-426e-8b6d-27e1db2ded75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Athena. How can I help you today?"
     ]
    }
   ],
   "source": [
    "response = ''\n",
    "tool_calls = {}\n",
    "\n",
    "for chunk in chain.stream(inputs):\n",
    "    response += chunk.content\n",
    "    print(chunk.content, end='', flush=True)\n",
    "    \n",
    "    extract_tool_content(chunk, tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28b85c8a-bc25-420a-a322-4e2a4c9686e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "128645b2-a673-4bb3-8e65-90d81cef707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Athena. How can I help you today?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e207cab-7f38-4f26-af0a-d81104a0b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"assistant_name\": \"Athena\",\n",
    "    \"user_input\": \"What's the weather like in Athens Greece and what your name?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f67739a0-f068-49b8-8530-d7b9572920d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ''\n",
    "tool_calls = {}\n",
    "\n",
    "for chunk in chain.stream(inputs):\n",
    "    response += chunk.content\n",
    "    print(chunk.content, end='', flush=True)\n",
    "    \n",
    "    extract_tool_content(chunk, tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "545c8a7c-0aa2-45ab-8bb4-3ef0eb19feee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'name': 'get_weather',\n",
       "  'args': '{\"location\": \"Athens, Greece\"}',\n",
       "  'id': 'call_EqTmQy99WODEgdhrQdCKToPB'}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b35ec535-87f9-4980-a4f4-02a49295f83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca86bac-a959-4c12-adb3-b69a6ca2eafe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chain with Structure Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d80e9f3f-db3c-4dae-9fce-5e532be48d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_llm = ChatOpenAI(model=MODEL_NAME).with_structured_output(AnalyzerOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "823d487f-ec8d-41c8-8132-ac5a8515bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_chain = analyzer_prompt | analyzer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a90cc8ce-3ffe-4c4b-be51-162eecb4eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(classification='Non-Religious', key_topics=['Greetings', 'Salutation'], context_requirements=\"The query 'Hello' is a simple greeting with no additional context provided, and it does not contain religious themes or specific topics. More context would be needed if the query intended to delve into religious or complex topics.\", query_complexity='Low', reasoning=\"The query 'Hello' is a basic greeting and does not include any religious themes, practices, or terminology. It is classified as non-religious and is considered a low complexity query involving common conversational language.\")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = analyzer_chain.invoke('Hello')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d575e64-63b6-45cd-b4b3-70e2a78211be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Religious \n",
      "\n",
      "\n",
      "The query 'Hello' is a simple greeting with no additional context provided, and it does not contain religious themes or specific topics. More context would be needed if the query intended to delve into religious or complex topics. \n",
      "\n",
      "\n",
      "['Greetings', 'Salutation'] \n",
      "\n",
      "\n",
      "Low \n",
      "\n",
      "\n",
      "The query 'Hello' is a basic greeting and does not include any religious themes, practices, or terminology. It is classified as non-religious and is considered a low complexity query involving common conversational language. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text.classification, '\\n\\n')\n",
    "print(text.context_requirements, '\\n\\n')\n",
    "print(text.key_topics, '\\n\\n')\n",
    "print(text.query_complexity, '\\n\\n')\n",
    "print(text.reasoning, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db5bc60a-d440-4e68-a981-260438ca96d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.AnalyzerOutput"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af5453d9-f5b2-4811-91a7-cb7c6ba9e0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query 'Hello' is a basic greeting and does not include any religious themes, practices, or terminology. It is classified as non-religious and is considered a low complexity query involving common conversational language.\n",
      "\n",
      "The analysis of the user query shows that the question is Non-Religious and with a Low complexity. Specifically, the analysis said the following: The query 'Hello' is a simple greeting with no additional context provided, and it does not contain religious themes or specific topics. More context would be needed if the query intended to delve into religious or complex topics. Key topics: Greetings, Salutation.\n"
     ]
    }
   ],
   "source": [
    "analysis_report = (\n",
    "    f\"{text.reasoning}\\n\\n\"\n",
    "    f\"The analysis of the user query shows that the question is {text.classification} \"\n",
    "    f\"and with a {text.query_complexity} complexity. Specifically, the analysis said the following: \"\n",
    "    f\"{text.context_requirements} Key topics: {', '.join(text.key_topics)}.\"\n",
    ")\n",
    "print(analysis_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb284e-9314-45aa-9c80-6067956f7544",
   "metadata": {},
   "source": [
    "## Agentic Roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963b298-0900-4f48-81e4-711b2b298024",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summarizer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20d9c846-8f0c-4853-b220-042d79c6f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e9f6c31-6dca-47d1-b54d-130cfcd01643",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant called Summarization Agent that takes multiple retrieved text chunks related to a user query \"\n",
    "            \"and generates a concise and informative summary. \"\n",
    "            \"Your goal is to synthesize the content, extract key themes, facts, and insights, and present them in a well-structured summary along with citations if possible. \"\n",
    "            \"Avoid repetition, remove irrelevant details, and prioritize clarity, coherence, and theological accuracy when applicable.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the list of retrieved contents:\\n\\n{retrieved_chunks}\\n\\n\"\n",
    "            \"Summarize the content in a clear, structured way. Highlight key points, theological concepts, and any important distinctions. \"\n",
    "            \"Make sure the summary is helpful for answering the user's original question.\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e7411d-e1fa-4d43-b3cb-bb91345427c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- The Orthodox Church believes that icons are a window to the divine and play a vital role in worship.\\n\\n- Icons are venerated, not worshipped, and serve as tools for teaching and spiritual reflection.\\n\\n- The Seventh Ecumenical Council affirmed the use of icons in 787 AD, emphasizing their doctrinal importance.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_chunks = [\n",
    "    \"The Orthodox Church believes that icons are a window to the divine and play a vital role in worship.\",\n",
    "    \"Icons are venerated, not worshipped, and serve as tools for teaching and spiritual reflection.\",\n",
    "    \"The Seventh Ecumenical Council affirmed the use of icons in 787 AD, emphasizing their doctrinal importance.\"\n",
    "]\n",
    "\n",
    "formatted_chunks = \"\\n\\n\".join(f\"- {chunk}\" for chunk in retrieved_chunks)\n",
    "formatted_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad2350c8-e27e-4d5c-9604-f9dc29bd40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(model=REASONING_LLM_NAME,\n",
    "                 name=\"Summarizer Agent\")\n",
    "\n",
    "llm = ChatOpenAI(model=LLM_NAME,\n",
    "                 name=\"Summarizer Agent\",\n",
    "                 temperature=.8)\n",
    "\n",
    "summarizer_agent = summarizer_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe22b813-0b10-4e64-80c5-b7003752665b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The retrieved texts emphasize several important points about icons in the Orthodox Church:\n",
      "\n",
      "1. Icons are viewed as a window to the divine, playing a crucial role in worship by facilitating a connection between the believer and the sacred.\n",
      "2. They are venerated—not worshipped—which means they are respected as aids for teaching and spiritual reflection, rather than being objects of divine adoration themselves.\n",
      "3. The legitimacy and doctrinal value of icons were affirmed by the Seventh Ecumenical Council in 787 AD, underscoring their significance in the Church's tradition and theology (see texts 1, 2, and 3)."
     ]
    }
   ],
   "source": [
    "for token in summarizer_agent.stream(retrieved_chunks):\n",
    "    print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e900ec-03eb-4c87-a443-41b734150f3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Query Generation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea63fa95-18e2-4777-839f-dd1f02a66e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46bbe94b-836c-4588-ab5d-ff49a4b019b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalQueriesOutput(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"A list of concise and semantically meaningful queries derived from the user's original input, intended for searching in a vector database.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26d6847e-0beb-4daa-8824-4e4e242556e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_generator_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are an AI assistant called Retrieval Query Generator Agent that transforms user queries or instructions into a list of optimized retrieval queries. \"\n",
    "            \"These queries will be used to search a vector database for relevant information. \"\n",
    "            \"Ensure the queries are semantically rich, diverse if needed, and focused on capturing different possible interpretations or relevant subtopics. \"\n",
    "            \"Consider different angles and nuances of the user instruction, and aim for clarity and precision in each query.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\", \n",
    "            \"User input: {user_input}\\n\\n\"\n",
    "            \"Generate a list of search queries in natural language that capture the key aspects of the input. \"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2607acc2-6184-4ca8-abc5-79759b44a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=REASONING_LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Retrieval_Agent\"\n",
    ").with_structured_output(RetrievalQueriesOutput)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Retrieval_Agent\",\n",
    "    temperature=0\n",
    ").with_structured_output(RetrievalQueriesOutput)\n",
    "\n",
    "retrieval_agent = query_generator_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c605ad2-c6b4-421d-9622-efad598f1db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQueriesOutput(queries=['What role do icons play in the worship practices of the Orthodox Church?', 'How do icons influence the spiritual life and rituals in Orthodox liturgy?', 'What is the theological significance of icons in Eastern Orthodox worship?', 'In what ways are icons used to convey religious meaning in Orthodox traditions?', 'How are icons venerated and what symbolism do they hold in Orthodox Christian worship?', 'What is the historical and cultural importance of icons in the context of Orthodox worship?', 'How does the use of icons in Orthodox churches enhance the spiritual experience of believers?'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Explain the significance of icons in Orthodox worship.\"\n",
    "response = retrieval_agent.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "863b33d3-ff1f-4f4e-be97-3ba12f9e2d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What role do icons play in the worship practices of the Orthodox Church?',\n",
       " 'How do icons influence the spiritual life and rituals in Orthodox liturgy?',\n",
       " 'What is the theological significance of icons in Eastern Orthodox worship?',\n",
       " 'In what ways are icons used to convey religious meaning in Orthodox traditions?',\n",
       " 'How are icons venerated and what symbolism do they hold in Orthodox Christian worship?',\n",
       " 'What is the historical and cultural importance of icons in the context of Orthodox worship?',\n",
       " 'How does the use of icons in Orthodox churches enhance the spiritual experience of believers?']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b1437-16a4-49c3-9c4f-f16a96193979",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a88b390-9dac-4b25-b09c-1279c1b83dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caf6f5f6-1639-4015-872a-20eab3b6d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzerOutput(BaseModel):\n",
    "    classification: Literal[\"Religious\", \"Non-Religious\"] = Field(..., description=\"Either 'Religious' or 'Non-Religious'\")\n",
    "    key_topics: List[str] = Field(..., description=\"List of key topics/areas related to the user's question (e.g., theology, jesus, humility, virtues)\",)\n",
    "    context_requirements: str = Field(..., description=\"A clear explanation of the query's context needs\")\n",
    "    query_complexity: Literal[\"Low\", \"Medium\", \"High\"] = Field(..., description=\"'Low', 'Medium', or 'High' complexity\")\n",
    "    reasoning: str = Field(..., description=\"The Chain of Thought that has been done in order to analyze the user query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1de0a0dd-ebee-43cf-b95c-bc47cc583642",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant that classifies user queries as either religious or non-religious and extracts key topics.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Classify the following query and extract key concepts:\\n\\nQuery: {query}\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "598d93f3-0a25-4a7d-b494-a939775df867",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=REASONING_LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Analyzer_Agent\"\n",
    ").with_structured_output(AnalyzerOutput)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Analyzer_Agent\",\n",
    "    temperature=0\n",
    ").with_structured_output(AnalyzerOutput)\n",
    "\n",
    "analyzer_agent = analyzer_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "934d2926-d423-4f19-b662-7b38f6c8c5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(classification='Religious', key_topics=['icons', 'Orthodox worship', 'religious symbolism', 'theology'], context_requirements='The query requires an explanation of the theological and liturgical role of icons in Orthodox worship, including historical and doctrinal context regarding their significance.', query_complexity='Low', reasoning='The query specifically asks about the significance of icons within Orthodox worship, indicating a focus on religious practices and symbolism. This clearly situates the question in a religious context, and the topics involved (icons, worship, symbolism) are directly related to religious studies.')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = analyzer_agent.invoke('Explain the significance of icons in Orthodox worship.')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c153ea6a-a47b-42d9-a543-2e3cb1ea374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Religious \n",
      "\n",
      "\n",
      "The query requires an explanation of the theological and liturgical role of icons in Orthodox worship, including historical and doctrinal context regarding their significance. \n",
      "\n",
      "\n",
      "['icons', 'Orthodox worship', 'religious symbolism', 'theology'] \n",
      "\n",
      "\n",
      "Low \n",
      "\n",
      "\n",
      "The query specifically asks about the significance of icons within Orthodox worship, indicating a focus on religious practices and symbolism. This clearly situates the question in a religious context, and the topics involved (icons, worship, symbolism) are directly related to religious studies. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.classification, '\\n\\n')\n",
    "print(response.context_requirements, '\\n\\n')\n",
    "print(response.key_topics, '\\n\\n')\n",
    "print(response.query_complexity, '\\n\\n')\n",
    "print(response.reasoning, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01b872-b418-41d8-b5a7-71f44e1c2d03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reflection Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7655213-cbca-4b48-8652-1820c9ebdd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54268695-2ca4-40e8-8b0d-6b2f792c213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionOutput(BaseModel):\n",
    "    reflection: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Detailed commentary on the final answer. Should analyze the correctness, clarity, and completeness \"\n",
    "            \"of the answer, and note any missing information or conflicting details.\")\n",
    "    )\n",
    "    requires_additional_retrieval: bool = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"If True, indicates the final answer did not fully address the user's query, and the agent should \"\n",
    "            \"re-run the retrieval process to gather more context or data.\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a29b3617-315b-4f59-9464-bafc32fd9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a reflection agent. Your goal is to assess the final answer produced by the previous generation step. \"\n",
    "            \"Review the user's original query and the generated answer. Provide a thoughtful reflection on the answer’s correctness, \"\n",
    "            \"clarity, completeness, and any areas that could be improved or expanded.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"User Query:\\n{user_query}\\n\\n\"\n",
    "            \"Generated Answer:\\n{generated_answer}\\n\\n\"\n",
    "            \"Reflect on this answer, noting if it fully addresses the user's question, whether there are any gaps or inaccuracies, \"\n",
    "            \"and if further clarification is necessary. Provide your analysis.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0274229-4b61-4c90-8286-d29f3b9fe384",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=REASONING_LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Reflection_Agent\"\n",
    ").with_structured_output(ReflectionOutput)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Reflection_Agent\",\n",
    "    temperature=0\n",
    ").with_structured_output(ReflectionOutput)\n",
    "\n",
    "reflection_agent = reflection_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09eed6b9-3e28-4f7f-a77d-c7b11ef8fe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReflectionOutput(reflection=\"The answer provided is clear, accurate, and addresses the core aspects of the significance of icons in Orthodox worship. It correctly explains that icons serve as windows to the divine, are important aids for veneration and prayer, and play a role in theological teaching by linking worshippers with the Incarnate Christ. The explanation that icons are not worshipped as idols but are venerated, with the honor transferred to the prototype they represent, is essential and was properly included. Additionally, the reference to the Seventh Ecumenical Council (787 AD) helps to anchor the explanation in historical and doctrinal context. One possible area for further elaboration might include expanding on the role of icons as visual theology and spiritual aids that help the faithful to connect with the mysteries of faith, or mentioning their aesthetic importance in liturgical settings, which would add greater depth to the answer. Overall, the answer is thorough and meets the user's query effectively.\", requires_additional_retrieval=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"user_query\": \"What is the significance of icons in Orthodox worship?\",\n",
    "    \"generated_answer\": \"Icons in Orthodox Christianity are viewed as windows to the divine, \"\n",
    "        \"serving as important aids for veneration, prayer, and theological teaching. \"\n",
    "        \"They are treated with great respect, though not worshiped as idols. \"\n",
    "        \"Historically, the Seventh Ecumenical Council (787 AD) affirmed the use of icons, \"\n",
    "        \"emphasizing their doctrinal importance. This council clarified that the honor \"\n",
    "        \"shown to an icon passes on to the prototype it represents, aligning the practice \"\n",
    "        \"with Orthodox teachings on the Incarnation and the sanctification of matter.\"\n",
    "}\n",
    "reflection = reflection_agent.invoke(input=inputs)\n",
    "reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98e8764d-a343-49d4-b1dc-511973b25b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer provided is clear, accurate, and addresses the core aspects of the significance of icons in Orthodox worship. It correctly explains that icons serve as windows to the divine, are important aids for veneration and prayer, and play a role in theological teaching by linking worshippers with the Incarnate Christ. The explanation that icons are not worshipped as idols but are venerated, with the honor transferred to the prototype they represent, is essential and was properly included. Additionally, the reference to the Seventh Ecumenical Council (787 AD) helps to anchor the explanation in historical and doctrinal context. One possible area for further elaboration might include expanding on the role of icons as visual theology and spiritual aids that help the faithful to connect with the mysteries of faith, or mentioning their aesthetic importance in liturgical settings, which would add greater depth to the answer. Overall, the answer is thorough and meets the user's query effectively.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(reflection.reflection)\n",
    "print(reflection.requires_additional_retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5169c93a-c779-4a2c-b698-94dfffd71e55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799a30d6-c8c5-420c-8929-1ce8dea9dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REASONING_LLM_NAME = \"o3-mini\"\n",
    "LLM_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438a7c1f-7771-4745-8187-30e1a05b43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are an AI assistant called Generation Agent with extensive knowledge of Christian Orthodox theology and history. \"\n",
    "            \"You have been provided with the user's question and a summarized context derived from relevant sources. \"\n",
    "            \"Use the information in the summary to ensure your answer is accurate, coherent, and consistent with the described theological points.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"User query: {user_query}\\n\\n\"\n",
    "            \"Relevant content summary:\\n{retrieved_summary}\\n\\n\"\n",
    "            \"Based on the above summary and your own knowledge, provide a complete and accurate answer. \"\n",
    "            \"If the summary does not contain the required detail, do your best to fill in the gaps using your background knowledge, \"\n",
    "            \"staying consistent with the theological principles outlined.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4097b6a0-f698-4fd6-953d-bb5cd71187f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=REASONING_LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Generation_Agent\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_NAME,\n",
    "    streaming=True,\n",
    "    name=\"Generation_Agent\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "generation_agent = generation_prompt | reasoning_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4782aa7-c6be-43e2-b01e-f0c08b79d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_inputs = {\n",
    "    \"user_query\": \"How do icons fit into Orthodox worship?\",\n",
    "    \"retrieved_summary\": (\n",
    "        \"From the retrieved sources: Icons are integral to Orthodox Christian practice, \"\n",
    "        \"functioning as tangible reflections of the Incarnation. They are venerated \"\n",
    "        \"(not worshiped), with the understanding that honor paid to an icon passes \"\n",
    "        \"on to the individual or event depicted. Historically, the Seventh Ecumenical \"\n",
    "        \"Council in 787 AD affirmed the use of icons, emphasizing their doctrinal and \"\n",
    "        \"liturgical importance in teaching and worship.\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8e469a-58e8-4754-9630-e5256c79a61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Orthodox Christianity, icons hold a central place in worship and spiritual life. They are not considered objects of worship in themselves; rather, icons are venerated as windows to the divine, offering a tangible reflection of the Incarnation. When the faithful show honor to an icon, the veneration is understood to be directed toward the person or event it represents.\n",
      "\n",
      "The Seventh Ecumenical Council in 787 AD affirmed the use of icons as a legitimate and essential part of Orthodox practice. This council taught that icons serve not only as artistic representations but also as theological tools. They help convey the mystery of God’s intervention in human history—most notably, the incarnation of Christ—making divine realities accessible to the human mind and heart.\n",
      "\n",
      "In the liturgical context, icons are used to focus prayer, aid in meditation, and connect the worshiper with the saints and holy events of salvation history. They provide a visual reminder that God entered into human nature, which underpins the entire Orthodox understanding of salvation. Thus, icons play both an educational and a devotional role: They instruct the faithful in the tenets of the faith and support a spiritual encounter with God.\n",
      "\n",
      "In summary:\n",
      "• Icons serve as a visible link between heaven and earth, symbolizing the reality of the Incarnation.\n",
      "• They are venerated (honored) rather than worshiped, with the honor given to the icon passed on to its subject.\n",
      "• Historically, their use was defended and affirmed by the Church, particularly through the Seventh Ecumenical Council, highlighting their role in teaching and expressing the faith.\n",
      "\n",
      "This understanding underscores why icons remain indispensable in Orthodox worship—they continue to inspire and sustain the spiritual life of the community by connecting the material with the transcendent."
     ]
    }
   ],
   "source": [
    "for token in generation_agent.stream(input=generation_inputs):\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9f0d8-fef3-4007-809c-45a7b76cd66a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Langchain Prebuild Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45d623-7a65-4940-8126-9746fe9495b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### React Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca87920c-cdb5-4801-8cbd-4bbe5fee2a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostasbouros/.local/lib/python3.10/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to create an image of a Halloween night set in a haunted museum. I want the image to embody a spooky atmosphere with details such as eerie lighting, ghostly apparitions, ancient exhibits, cobwebs, and flickering candles that enhance the haunted vibe of the scene.\n",
      "\n",
      "Action: openai_dalle  \n",
      "Action Input: \"A Halloween night at a haunted museum, eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs and flickering candles, full moon in the background creating a spooky atmosphere, detailed and atmospheric.\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-2qwmDV9Ve2gTEzSZLdQ14cEq.png?st=2025-04-11T21%3A41%3A58Z&se=2025-04-11T23%3A41%3A58Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T20%3A07%3A09Z&ske=2025-04-12T20%3A07%3A09Z&sks=b&skv=2024-08-04&sig=0IbVLA5qZFo/dhULmDiiUDJHqM4UJceg4GMNSCD2w6Y%3D\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: Create an image of a Halloween night at a haunted museum  \n",
      "Thought: I need to create an image that captures a spooky atmosphere at a haunted museum during Halloween. I envision eerie lighting, ghostly apparitions, ancient exhibits, cobwebs, and flickering candles, all under a full moon to enhance the haunted ambiance.  \n",
      "Action: openai_dalle  \n",
      "Action Input: \"A Halloween night at a haunted museum, eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs and flickering candles, full moon in the background creating a spooky atmosphere, detailed and atmospheric.\"  \u001b[0m\u001b[36;1m\u001b[1;3mhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-HFvQNYd8PIrEtzo1yql8PxHK.png?st=2025-04-11T21%3A42%3A13Z&se=2025-04-11T23%3A42%3A13Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T16%3A50%3A47Z&ske=2025-04-12T16%3A50%3A47Z&sks=b&skv=2024-08-04&sig=GZZiMWtGBcrSfVFcxMjsnT%2BC11iUWnxmg4Zk8YNUjrA%3D\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to create an image depicting a Halloween night in a haunted museum. The image should include eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs, and flickering candles, all illuminated by a full moon to create a spooky atmosphere.\n",
      "Action: openai_dalle\n",
      "Action Input: \"A Halloween night at a haunted museum, eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs and flickering candles, full moon in the background creating a spooky atmosphere, detailed and atmospheric.\"\u001b[0m\u001b[36;1m\u001b[1;3mhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-WQQByALWZYBniUuUXTfo7ehG.png?st=2025-04-11T21%3A42%3A34Z&se=2025-04-11T23%3A42%3A34Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T07%3A09%3A31Z&ske=2025-04-12T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=jBasG%2BIdDVJqT0qKCsavtlHxSHqm8MhD1V0%2BRgfhgfQ%3D\u001b[0m\u001b[32;1m\u001b[1;3mThought: I generated a detailed image according to the description: a Halloween night at a haunted museum with eerie lighting, ghostly apparitions drifting among ancient exhibits, cobwebs, flickering candles, and a full moon casting a spooky glow over the scene.\n",
      "Final Answer: Here is your image of a Halloween night at a haunted museum:\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-WQQByALWZYBniUuUXTfo7ehG.png?st=2025-04-11T21%3A42%3A34Z&se=2025-04-11T23%3A42%3A34Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T07%3A09%3A31Z&ske=2025-04-12T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=jBasG%2BIdDVJqT0qKCsavtlHxSHqm8MhD1V0%2BRgfhgfQ%3D\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final Result:\n",
      " {'input': 'Create an image of a Halloween night at a haunted museum', 'output': 'Here is your image of a Halloween night at a haunted museum:\\nhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-WQQByALWZYBniUuUXTfo7ehG.png?st=2025-04-11T21%3A42%3A34Z&se=2025-04-11T23%3A42%3A34Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T07%3A09%3A31Z&ske=2025-04-12T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=jBasG%2BIdDVJqT0qKCsavtlHxSHqm8MhD1V0%2BRgfhgfQ%3D'}\n"
     ]
    }
   ],
   "source": [
    "# Tool\n",
    "from langchain_community.tools.openai_dalle_image_generation import OpenAIDALLEImageGenerationTool\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "\n",
    "# Ready prompt for react agent\n",
    "from langchain import hub\n",
    "\n",
    "# ReAct Agent\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"o3-mini\")\n",
    "\n",
    "# DALL·E Tool\n",
    "dalle_tool = OpenAIDALLEImageGenerationTool(api_wrapper=DallEAPIWrapper())\n",
    "tools = [dalle_tool]\n",
    "\n",
    "# Agent\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Wrap in executor\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Run\n",
    "user_prompt = \"Create an image of a Halloween night at a haunted museum\"\n",
    "response = executor.invoke({\"input\": user_prompt})\n",
    "\n",
    "print(\"\\nFinal Result:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a4bb30-a4f8-48e6-8e76-905ed2952de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your image of a Halloween night at a haunted museum:\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-17EWipzKV90CDRB8UjVoCjKZ/user-upUKnaSCl1NVGsGh841k3e6l/img-WQQByALWZYBniUuUXTfo7ehG.png?st=2025-04-11T21%3A42%3A34Z&se=2025-04-11T23%3A42%3A34Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-11T07%3A09%3A31Z&ske=2025-04-12T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=jBasG%2BIdDVJqT0qKCsavtlHxSHqm8MhD1V0%2BRgfhgfQ%3D\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b78961a-f6ce-45e2-aaa9-7b97632cd73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAction(tool='openai_dalle', tool_input='A spooky haunted museum on a Halloween night, with ghostly apparitions, eerie antique exhibits, dim lighting, pumpkins, and cobwebs, surrounded by a misty, mysterious atmosphere.', log='Question: Create an image of a Halloween night at a haunted museum  \\nThought: I need to generate an image that conveys a spooky, atmospheric setting typical of a haunted museum on Halloween night. I will include elements such as eerie lighting, ghostly apparitions, ancient exhibits, pumpkins, and cobwebs to capture the haunted ambiance.  \\nAction: openai_dalle  \\nAction Input: \"A spooky haunted museum on a Halloween night, with ghostly apparitions, eerie antique exhibits, dim lighting, pumpkins, and cobwebs, surrounded by a misty, mysterious atmosphere.\"  ')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\n",
    "    \"input\": user_prompt,\n",
    "    \"intermediate_steps\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0af0fa4a-481c-4873-9e29-41b674b79b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e35e83-e483-4782-874b-e33ce7a8b40a",
   "metadata": {},
   "source": [
    "## LangGraph Prebuild Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c1b6e-6995-4b36-a7ad-c665450bd3f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c1d0e8-510e-4f56-9a12-e5ba4fa43fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0801a57-a4b5-46a2-918b-6ae0f1afcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}'\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], \n",
    "    subject: str, \n",
    "    duration_minutes: int, \n",
    "    preferred_day: str\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    return f\"Meeting '{subject}' scheduled for {preferred_day} with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1418c3d5-0969-4b0e-8def-26fb13e3974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=\"openai:o3-mini\",\n",
    "    tools=[write_email, schedule_meeting, check_calendar_availability],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d8f43d2-9964-4342-8347-9dbb71a19634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='write me an email from my director to thank him for his kind words pls', additional_kwargs={}, response_metadata={}, id='22303341-2fb9-4507-8c1d-421a00ad5c61'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uDnNeQXlyKJLtwfRyshBcSRz', 'function': {'arguments': '{\\n  \"to\": \"director@example.com\",\\n  \"subject\": \"Thank You for Your Kind Words\",\\n  \"content\": \"Dear [Director\\'s Name],\\\\n\\\\nI hope this message finds you well. I wanted to take a moment to express my sincere gratitude for your kind words and encouragement. Your feedback has not only boosted my confidence but also reinforced my commitment to contributing in every possible way to our team’s success.\\\\n\\\\nYour thoughtful reminder of the positive impact my work can have means a great deal to me, and it inspires me to strive for even higher standards. I truly appreciate your leadership and the supportive work environment you help foster.\\\\n\\\\nThank you once again for your kind words and for always being a source of guidance. I look forward to continuing to work together and to progressing further under your mentorship.\\\\n\\\\nWarm regards,\\\\n[Your Name]\"\\n}', 'name': 'write_email'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1283, 'prompt_tokens': 124, 'total_tokens': 1407, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1088, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_99801fd0cf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2930f600-b5ac-499a-a119-abe273cccfb5-0', tool_calls=[{'name': 'write_email', 'args': {'to': 'director@example.com', 'subject': 'Thank You for Your Kind Words', 'content': \"Dear [Director's Name],\\n\\nI hope this message finds you well. I wanted to take a moment to express my sincere gratitude for your kind words and encouragement. Your feedback has not only boosted my confidence but also reinforced my commitment to contributing in every possible way to our team’s success.\\n\\nYour thoughtful reminder of the positive impact my work can have means a great deal to me, and it inspires me to strive for even higher standards. I truly appreciate your leadership and the supportive work environment you help foster.\\n\\nThank you once again for your kind words and for always being a source of guidance. I look forward to continuing to work together and to progressing further under your mentorship.\\n\\nWarm regards,\\n[Your Name]\"}, 'id': 'call_uDnNeQXlyKJLtwfRyshBcSRz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 124, 'output_tokens': 1283, 'total_tokens': 1407, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1088}}),\n",
       "  ToolMessage(content=\"Email sent to director@example.com with subject 'Thank You for Your Kind Words'\", name='write_email', id='fc8504d8-0278-4442-907a-5f7988e452f9', tool_call_id='call_uDnNeQXlyKJLtwfRyshBcSRz'),\n",
       "  AIMessage(content='The email has been sent to your director. Let me know if you need any further assistance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 331, 'total_tokens': 362, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_99801fd0cf', 'finish_reason': 'stop', 'logprobs': None}, id='run-893bcc69-523e-46a8-bb95-8885c841eed4-0', usage_metadata={'input_tokens': 331, 'output_tokens': 31, 'total_tokens': 362, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"write me an email from my director to thank him for his kind words pls\"\n",
    "response = agent.invoke({\"messages\": query})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91719c32-361f-4983-8eb6-288000cd549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "write me an email from my director to thank him for his kind words pls\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_email (call_uDnNeQXlyKJLtwfRyshBcSRz)\n",
      " Call ID: call_uDnNeQXlyKJLtwfRyshBcSRz\n",
      "  Args:\n",
      "    to: director@example.com\n",
      "    subject: Thank You for Your Kind Words\n",
      "    content: Dear [Director's Name],\n",
      "\n",
      "I hope this message finds you well. I wanted to take a moment to express my sincere gratitude for your kind words and encouragement. Your feedback has not only boosted my confidence but also reinforced my commitment to contributing in every possible way to our team’s success.\n",
      "\n",
      "Your thoughtful reminder of the positive impact my work can have means a great deal to me, and it inspires me to strive for even higher standards. I truly appreciate your leadership and the supportive work environment you help foster.\n",
      "\n",
      "Thank you once again for your kind words and for always being a source of guidance. I look forward to continuing to work together and to progressing further under your mentorship.\n",
      "\n",
      "Warm regards,\n",
      "[Your Name]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_email\n",
      "\n",
      "Email sent to director@example.com with subject 'Thank You for Your Kind Words'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The email has been sent to your director. Let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431604c6-4c21-4610-b61a-cb5140f7a8d8",
   "metadata": {},
   "source": [
    "### Reflection Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28b17f-51eb-4688-92f7-93b5600195c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec720c-f24e-41b1-8886-2c0a9073d4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19de5d6-3cd4-4387-8120-09557c691263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03082d41-2754-480a-acd0-50b756705024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
